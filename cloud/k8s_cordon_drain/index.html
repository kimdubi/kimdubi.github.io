<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>kubernetes Pod Scheduling - cordon & drain | kimDuBiA</title><meta name=keywords content="kubernetes"><meta name=description content="혼자 쿠버네티스 정리를 위한 글 오늘은 cordon, drain 편
특정 node의 점검, 정책 변경 등으로 특정 노드에 있는 pod들을 다른 노드로 옮기거나
작업시간 동안 특정 node에는 Pod scheduling 을 막아놓을 필요가 있을 때 사용하는 기능이 cordon과 drain이다.
cordon cordon 은 지정한 node에 pod scheduling 되는 것을 막는 기능임
 cordon 설정  $ kubectl get deploy,pod NAME READY UP-TO-DATE AVAILABLE AGE deployment.apps/redis-deployment2 2/2 2 2 22h NAME READY STATUS RESTARTS AGE pod/redis-deployment2-6bcb64f4d4-lq5pc 1/1 Running 0 22h pod/redis-deployment2-6bcb64f4d4-sq6vb 1/1 Running 0 22h $ kubectl cordon minikube node/minikube cordoned $ kubectl get node NAME STATUS ROLES AGE VERSION minikube Ready,SchedulingDisabled master 6d18h v1."><meta name=author content="kimdubi"><link rel=canonical href=/cloud/k8s_cordon_drain/><meta name=google-site-verification content="XYZabc"><meta name=yandex-verification content="XYZabc"><meta name=msvalidate.01 content="XYZabc"><link crossorigin=anonymous href=/assets/css/stylesheet.min.2dbef8664bbfb3e83a0a44fd4a8fc5010240dbcd1dbc1400753b928b497b8f5e.css integrity="sha256-Lb74Zku/s+g6CkT9So/FAQJA280dvBQAdTuSi0l7j14=" rel="preload stylesheet" as=style><script defer crossorigin=anonymous src=/assets/js/highlight.min.27cd435cc9ed6abb4b496581b151804f79f366c412620272bb94e2f5f598ebcc.js integrity="sha256-J81DXMntartLSWWBsVGAT3nzZsQSYgJyu5Ti9fWY68w=" onload=hljs.initHighlightingOnLoad();></script><link rel=icon href=%3Clink%20/%20abs%20url%3E><link rel=icon type=image/png sizes=16x16 href=%3Clink%20/%20abs%20url%3E><link rel=icon type=image/png sizes=32x32 href=%3Clink%20/%20abs%20url%3E><link rel=apple-touch-icon href=%3Clink%20/%20abs%20url%3E><link rel=mask-icon href=%3Clink%20/%20abs%20url%3E><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><meta name=generator content="Hugo 0.80.0"><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme: rgb(29, 30, 32);--entry: rgb(46, 46, 51);--primary: rgb(218, 218, 219);--secondary: rgb(155, 156, 157);--tertiary: rgb(65, 66, 68);--content: rgb(196, 196, 197);--hljs-bg: rgb(46, 46, 51);--code-bg: rgb(55, 56, 62);--border: rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><script type=application/javascript>var doNotTrack=false;if(!doNotTrack){(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');ga('create','UA-123-45','auto');ga('send','pageview');}</script><meta property="og:title" content="kubernetes Pod Scheduling - cordon & drain"><meta property="og:description" content="혼자 쿠버네티스 정리를 위한 글 오늘은 cordon, drain 편
특정 node의 점검, 정책 변경 등으로 특정 노드에 있는 pod들을 다른 노드로 옮기거나
작업시간 동안 특정 node에는 Pod scheduling 을 막아놓을 필요가 있을 때 사용하는 기능이 cordon과 drain이다.
cordon cordon 은 지정한 node에 pod scheduling 되는 것을 막는 기능임
 cordon 설정  $ kubectl get deploy,pod NAME READY UP-TO-DATE AVAILABLE AGE deployment.apps/redis-deployment2 2/2 2 2 22h NAME READY STATUS RESTARTS AGE pod/redis-deployment2-6bcb64f4d4-lq5pc 1/1 Running 0 22h pod/redis-deployment2-6bcb64f4d4-sq6vb 1/1 Running 0 22h $ kubectl cordon minikube node/minikube cordoned $ kubectl get node NAME STATUS ROLES AGE VERSION minikube Ready,SchedulingDisabled master 6d18h v1."><meta property="og:type" content="article"><meta property="og:url" content="/cloud/k8s_cordon_drain/"><meta property="og:image" content="%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta property="article:section" content="cloud"><meta property="article:published_time" content="2021-10-06T09:17:51+09:00"><meta property="article:modified_time" content="2021-10-06T09:17:51+09:00"><meta property="og:site_name" content="kimDuBiA"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta name=twitter:title content="kubernetes Pod Scheduling - cordon & drain"><meta name=twitter:description content="혼자 쿠버네티스 정리를 위한 글 오늘은 cordon, drain 편
특정 node의 점검, 정책 변경 등으로 특정 노드에 있는 pod들을 다른 노드로 옮기거나
작업시간 동안 특정 node에는 Pod scheduling 을 막아놓을 필요가 있을 때 사용하는 기능이 cordon과 drain이다.
cordon cordon 은 지정한 node에 pod scheduling 되는 것을 막는 기능임
 cordon 설정  $ kubectl get deploy,pod NAME READY UP-TO-DATE AVAILABLE AGE deployment.apps/redis-deployment2 2/2 2 2 22h NAME READY STATUS RESTARTS AGE pod/redis-deployment2-6bcb64f4d4-lq5pc 1/1 Running 0 22h pod/redis-deployment2-6bcb64f4d4-sq6vb 1/1 Running 0 22h $ kubectl cordon minikube node/minikube cordoned $ kubectl get node NAME STATUS ROLES AGE VERSION minikube Ready,SchedulingDisabled master 6d18h v1."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":2,"name":"Clouds","item":"/cloud/"},{"@type":"ListItem","position":3,"name":"kubernetes Pod Scheduling - cordon \u0026 drain","item":"/cloud/k8s_cordon_drain/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"kubernetes Pod Scheduling - cordon \u0026 drain","name":"kubernetes Pod Scheduling - cordon \u0026 drain","description":"혼자 쿠버네티스 정리를 위한 글 오늘은 cordon, drain 편\n특정 node의 점검, 정책 변경 등으로 특정 노드에 있는 pod들을 다른 노드로 옮기거나\n작업시간 동안 특정 node에는 Pod scheduling 을 막아놓을 필요가 있을 때 사용하는 기능이 cordon과 drain이다.\ncordon cordon 은 지정한 node에 pod scheduling 되는 것을 막는 기능임\n cordon 설정  $ kubectl get deploy,pod NAME READY UP-TO-DATE AVAILABLE AGE deployment.apps/redis-deployment2 2/2 2 2 22h NAME READY STATUS RESTARTS AGE pod/redis-deployment2-6bcb64f4d4-lq5pc 1/1 Running 0 22h pod/redis-deployment2-6bcb64f4d4-sq6vb 1/1 Running 0 22h $ kubectl cordon minikube node/minikube cordoned $ kubectl get node NAME STATUS ROLES AGE VERSION minikube Ready,SchedulingDisabled master 6d18h v1.","keywords":["kubernetes"],"articleBody":" 혼자 쿠버네티스 정리를 위한 글 오늘은 cordon, drain 편\n특정 node의 점검, 정책 변경 등으로 특정 노드에 있는 pod들을 다른 노드로 옮기거나\n작업시간 동안 특정 node에는 Pod scheduling 을 막아놓을 필요가 있을 때 사용하는 기능이 cordon과 drain이다.\ncordon cordon 은 지정한 node에 pod scheduling 되는 것을 막는 기능임\n cordon 설정  $ kubectl get deploy,pod NAME READY UP-TO-DATE AVAILABLE AGE deployment.apps/redis-deployment2 2/2 2 2 22h NAME READY STATUS RESTARTS AGE pod/redis-deployment2-6bcb64f4d4-lq5pc 1/1 Running 0 22h pod/redis-deployment2-6bcb64f4d4-sq6vb 1/1 Running 0 22h $ kubectl cordon minikube node/minikube cordoned $ kubectl get node NAME STATUS ROLES AGE VERSION minikube Ready,SchedulingDisabled master 6d18h v1.17.0 = minikube node에 cordon 설정하자 SchedulingDisabled 상태가 됨\n scale 해보자  $ kubectl scale deployment.apps/redis-deployment2 --replicas=4 deployment.apps/redis-deployment2 scaled $ kubectl get deploy,pod NAME READY UP-TO-DATE AVAILABLE AGE deployment.apps/redis-deployment2 2/4 4 2 22h NAME READY STATUS RESTARTS AGE pod/redis-deployment2-6bcb64f4d4-h6vsl 0/1 Pending 0 6s pod/redis-deployment2-6bcb64f4d4-lb68q 0/1 Pending 0 6s pod/redis-deployment2-6bcb64f4d4-lq5pc 1/1 Running 0 22h pod/redis-deployment2-6bcb64f4d4-sq6vb 1/1 Running 0 22h = 기존에 떠있던 pod는 상관없지만 새로 추가로 띄운 2대의 pod은 pending 상태임, node가 단 하나인데 그걸 cordon해버렸으니..\n cordon 해제하면?  $ kubectl uncordon minikube node/minikube uncordoned $ kubectl get deploy,pod NAME READY UP-TO-DATE AVAILABLE AGE deployment.apps/redis-deployment2 2/4 4 2 22h deployment.apps/testnet 1/1 1 1 5d18h NAME READY STATUS RESTARTS AGE pod/redis-deployment2-6bcb64f4d4-h6vsl 0/1 ContainerCreating 0 97s pod/redis-deployment2-6bcb64f4d4-lb68q 0/1 ContainerCreating 0 97s pod/redis-deployment2-6bcb64f4d4-lq5pc 1/1 Running 0 22h pod/redis-deployment2-6bcb64f4d4-sq6vb 1/1 Running 0 22h = uncordon 하면 pending상태였던 pod이 다시 생성됨\ndrain drain 기능은 특정 node의 pod들을 다른 node로 이동시키는 기능으로 drain 수행 시\n해당 Node에 pod scheduling을 막고, 실행중이던 pod들을 삭제한다. 이 때 pod에서 수행되던 작업들이 정리될 때 까지 기다린 후 삭제한다. (graceful)\n  drain 안되는 세가지 경우\n  파드가 emptyDir을 사용하여 local data를 저장하는 경우\n= emptyDir를 사용하여 local data를 저장하는 파드가 해당 워커 노드에 있는 경우, 이 파드를 삭제 시 해당 데이터 또한 삭제되므로 수행되지 않습니다. 해당 파드가 제거되어도 문제가 없는 경우에는 –delete-local-data 플래그를 drain 명령어에 추가하여 수행합니다.\n  해당 워커 노드에 데몬셋(daemonset)이 구동되고 있는 경우\n= 데몬셋에 속한 파드가 해당 워커 노드에 구동되고 있는 경우, kubectl drain 명령이 수행되지 않습니다. 데몬셋 컨트롤러는 노드가 unschedulable 상태에 있더라도 이를 무시하고 해당 노드에 파드를 스케줄하여 배치할 수 있습니다. 데몬셋에 속한 파드가 있는 경우에는, –ignore-daemonsets 플래그를 추가하여 해당 파드를 축출 대상에서 제외할 수 있습니다.\n  Kubernetes의 컨트롤러에서 관리되지 않는 파드가 구동되고 있는 경우\n= Kubernetes에서는 Deployment, Statefulset, DaemonSet, ReplicaSet, Job과 같은 컨트롤러가 관리하지 않는 파드가 해당 워커 노드 상에 있는 경우, kubectl drain 명령어는 이를 보호하기 위해서 동작하지 않습니다. –force 플래그를 추가하여 kubectl drain 명령어를 실행하는 경우, 이러한 파드는 클러스터에서 제거되며 재스케줄링되지 않습니다.\n    drain 해보자\n  $ kubectl drain minikube node/minikube already cordoned error: unable to drain node \"minikube\", aborting command... There are pending nodes to be drained: minikube cannot delete DaemonSet-managed Pods (use --ignore-daemonsets to ignore): kube-system/kube-proxy-vxf7k cannot delete Pods not managed by ReplicationController, ReplicaSet, Job, DaemonSet or StatefulSet (use --force to override): kube-system/storage-provisioner cannot delete Pods with local storage (use --delete-local-data to override): kubernetes-dashboard/dashboard-metrics-scraper-7b64584c5c-mn29t, kubernetes-dashboard/kubernetes-dashboard-79d9cd965-rsbzn = 뭔가 demonset, 혹은 emptyDir을 사용하는 Pod 들이 있다며 drain이 안된다는 에러가 떴다. 처음보는 Pod들인데 그 내가 사용하는 namespace의 Pod들이 아니기 때문이다.\n$ kubectl get deploy,pod --all-namespaces NAMESPACE NAME READY UP-TO-DATE AVAILABLE AGE default deployment.apps/redis-deployment2 4/4 4 4 26h default deployment.apps/testnet 1/1 1 1 5d23h kube-system deployment.apps/coredns 2/2 2 2 6d23h kubernetes-dashboard deployment.apps/dashboard-metrics-scraper 1/1 1 1 6d23h kubernetes-dashboard deployment.apps/kubernetes-dashboard 1/1 1 1 6d23h NAMESPACE NAME READY STATUS RESTARTS AGE default pod/redis-deployment2-6bcb64f4d4-h6vsl 1/1 Running 0 4h34m default pod/redis-deployment2-6bcb64f4d4-lb68q 1/1 Running 0 4h34m default pod/redis-deployment2-6bcb64f4d4-lq5pc 1/1 Running 0 26h default pod/redis-deployment2-6bcb64f4d4-sq6vb 1/1 Running 0 26h default pod/testnet-5f694fd785-lb5x8 1/1 Running 1 5d23h kube-system pod/coredns-6955765f44-k6cv4 1/1 Running 0 6d23h kube-system pod/coredns-6955765f44-mg7xp 1/1 Running 0 6d23h kube-system pod/etcd-minikube 1/1 Running 0 6d23h kube-system pod/kube-addon-manager-minikube 1/1 Running 0 6d23h kube-system pod/kube-apiserver-minikube 1/1 Running 0 6d23h kube-system pod/kube-controller-manager-minikube 1/1 Running 5 6d23h kube-system pod/kube-proxy-vxf7k 1/1 Running 0 6d23h kube-system pod/kube-scheduler-minikube 1/1 Running 4 6d23h kube-system pod/storage-provisioner 1/1 Running 0 6d23h kubernetes-dashboard pod/dashboard-metrics-scraper-7b64584c5c-mn29t 1/1 Running 0 6d23h kubernetes-dashboard pod/kubernetes-dashboard-79d9cd965-rsbzn 1/1 Running 0 6d23h   옵션 추가하여 다시 drain 해보자  $ kubectl drain minikube --ignore-daemonsets=true --force --delete-local-data node/minikube already cordoned WARNING: deleting Pods not managed by ReplicationController, ReplicaSet, Job, DaemonSet or StatefulSet: kube-system/storage-provisioner; ignoring DaemonSet-managed Pods: kube-system/kube-proxy-vxf7k evicting pod \"testnet-5f694fd785-lb5x8\" evicting pod \"coredns-6955765f44-mg7xp\" evicting pod \"redis-deployment2-6bcb64f4d4-lb68q\" evicting pod \"storage-provisioner\" evicting pod \"kubernetes-dashboard-79d9cd965-rsbzn\" evicting pod \"coredns-6955765f44-k6cv4\" evicting pod \"redis-deployment2-6bcb64f4d4-h6vsl\" evicting pod \"redis-deployment2-6bcb64f4d4-lq5pc\" evicting pod \"redis-deployment2-6bcb64f4d4-sq6vb\" evicting pod \"dashboard-metrics-scraper-7b64584c5c-mn29t\" pod/dashboard-metrics-scraper-7b64584c5c-mn29t evicted pod/redis-deployment2-6bcb64f4d4-sq6vb evicted pod/redis-deployment2-6bcb64f4d4-h6vsl evicted pod/kubernetes-dashboard-79d9cd965-rsbzn evicted pod/testnet-5f694fd785-lb5x8 evicted pod/storage-provisioner evicted pod/redis-deployment2-6bcb64f4d4-lb68q evicted pod/coredns-6955765f44-k6cv4 evicted pod/redis-deployment2-6bcb64f4d4-lq5pc evicted pod/coredns-6955765f44-mg7xp evicted node/minikube evicted = minikube node 안에 있던 pod들이 쫓겨났다\n 다시 조회해보자  $ kubectl get deploy,pod --all-namespaces NAMESPACE NAME READY UP-TO-DATE AVAILABLE AGE default deployment.apps/redis-deployment2 0/4 4 0 27h default deployment.apps/testnet 0/1 1 0 5d23h kube-system deployment.apps/coredns 0/2 2 0 6d23h kubernetes-dashboard deployment.apps/dashboard-metrics-scraper 0/1 1 0 6d23h kubernetes-dashboard deployment.apps/kubernetes-dashboard 0/1 1 0 6d23h NAMESPACE NAME READY STATUS RESTARTS AGE default pod/redis-deployment2-6bcb64f4d4-8rzpc 0/1 Pending 0 15m default pod/redis-deployment2-6bcb64f4d4-j46d7 0/1 Pending 0 15m default pod/redis-deployment2-6bcb64f4d4-psksx 0/1 Pending 0 15m default pod/redis-deployment2-6bcb64f4d4-r64b7 0/1 Pending 0 15m default pod/testnet-5f694fd785-dv46g 0/1 Pending 0 15m kube-system pod/coredns-6955765f44-2pfdc 0/1 Pending 0 15m kube-system pod/coredns-6955765f44-59cp5 0/1 Pending 0 15m kube-system pod/etcd-minikube 1/1 Running 0 6d23h kube-system pod/kube-addon-manager-minikube 1/1 Running 0 6d23h kube-system pod/kube-apiserver-minikube 1/1 Running 0 6d23h kube-system pod/kube-controller-manager-minikube 1/1 Running 5 6d23h kube-system pod/kube-proxy-vxf7k 1/1 Running 0 6d23h kube-system pod/kube-scheduler-minikube 1/1 Running 4 6d23h kube-system pod/storage-provisioner 0/1 Pending 0 15m kubernetes-dashboard pod/dashboard-metrics-scraper-7b64584c5c-6dn8b 0/1 Pending 0 15m kubernetes-dashboard pod/kubernetes-dashboard-79d9cd965-25zcr 0/1 Pending 0 15m = node 가 minikube 하나라서 옮겨갈 곳이 없으니 전부 pending 상태임\n그리고 마스터노드의 kube-apiserver를 이용해서 생성된 것이 아닌 kubelet이 직접 실행한 static pod들은 상관없이 running 상태\n drain 설정 해제  $ kubectl uncordon minikube node/minikube uncordoned $ kubectl get deploy,pod --all-namespaces NAMESPACE NAME READY UP-TO-DATE AVAILABLE AGE default deployment.apps/redis-deployment2 4/4 4 4 27h default deployment.apps/testnet 1/1 1 1 5d23h kube-system deployment.apps/coredns 2/2 2 2 6d23h kubernetes-dashboard deployment.apps/dashboard-metrics-scraper 1/1 1 1 6d23h kubernetes-dashboard deployment.apps/kubernetes-dashboard 1/1 1 1 6d23h NAMESPACE NAME READY STATUS RESTARTS AGE default pod/redis-deployment2-6bcb64f4d4-8rzpc 1/1 Running 0 19m default pod/redis-deployment2-6bcb64f4d4-j46d7 1/1 Running 0 19m default pod/redis-deployment2-6bcb64f4d4-psksx 1/1 Running 0 19m default pod/redis-deployment2-6bcb64f4d4-r64b7 1/1 Running 0 19m default pod/testnet-5f694fd785-dv46g 1/1 Running 0 19m kube-system pod/coredns-6955765f44-2pfdc 1/1 Running 0 19m kube-system pod/coredns-6955765f44-59cp5 1/1 Running 0 19m kube-system pod/etcd-minikube 1/1 Running 0 6d23h kube-system pod/kube-addon-manager-minikube 1/1 Running 0 6d23h kube-system pod/kube-apiserver-minikube 1/1 Running 0 6d23h kube-system pod/kube-controller-manager-minikube 1/1 Running 5 6d23h kube-system pod/kube-proxy-vxf7k 1/1 Running 0 6d23h kube-system pod/kube-scheduler-minikube 1/1 Running 4 6d23h kube-system pod/storage-provisioner 1/1 Running 0 19m kubernetes-dashboard pod/dashboard-metrics-scraper-7b64584c5c-6dn8b 1/1 Running 0 19m kubernetes-dashboard pod/kubernetes-dashboard-79d9cd965-25zcr 1/1 Running 0 19m ","wordCount":"1051","inLanguage":"en","datePublished":"2021-10-06T09:17:51+09:00","dateModified":"2021-10-06T09:17:51+09:00","author":{"@type":"Person","name":"kimdubi"},"mainEntityOfPage":{"@type":"WebPage","@id":"/cloud/k8s_cordon_drain/"},"publisher":{"@type":"Organization","name":"kimDuBiA","logo":{"@type":"ImageObject","url":"%3Clink%20/%20abs%20url%3E"}}}</script></head><body id=top><script>if(localStorage.getItem("pref-theme")==="dark"){document.body.classList.add('dark');}else if(localStorage.getItem("pref-theme")==="light"){document.body.classList.remove('dark')}else if(window.matchMedia('(prefers-color-scheme: dark)').matches){document.body.classList.add('dark');}</script><header class=header><nav class=nav><div class=logo><a href accesskey=h title="Hi (Alt + H)">Hi</a>
<span class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></span></div><ul id=menu><li><a href=/ title=Home><span>Home</span></a></li><li><a href=/categories/ title=categories><span>categories</span></a></li><li><a href=/tags/ title=tags><span>tags</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href>Home</a>&nbsp;»&nbsp;<a href=/cloud/>Clouds</a></div><h1 class=post-title>kubernetes Pod Scheduling - cordon & drain</h1><div class=post-meta>October 6, 2021&nbsp;·&nbsp;5 min&nbsp;·&nbsp;kimdubi</div></header><div class=toc><details><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><ul><li><a href=#cordon aria-label=cordon>cordon</a></li><li><a href=#drain aria-label=drain>drain</a></li></ul></div></details></div><div class=post-content><hr><p>혼자 쿠버네티스 정리를 위한 글 오늘은 cordon, drain 편</p><p>특정 node의 점검, 정책 변경 등으로 특정 노드에 있는 pod들을 다른 노드로 옮기거나<br>작업시간 동안 특정 node에는 Pod scheduling 을 막아놓을 필요가 있을 때 사용하는 기능이 cordon과 drain이다.</p><h3 id=cordon>cordon<a hidden class=anchor aria-hidden=true href=#cordon>#</a></h3><p>cordon 은 지정한 node에 pod scheduling 되는 것을 막는 기능임</p><ul><li>cordon 설정</li></ul><pre><code>$ kubectl get deploy,pod
NAME                                READY   UP-TO-DATE   AVAILABLE   AGE
deployment.apps/redis-deployment2   2/2     2            2           22h

NAME                                     READY   STATUS    RESTARTS   AGE
pod/redis-deployment2-6bcb64f4d4-lq5pc   1/1     Running   0          22h
pod/redis-deployment2-6bcb64f4d4-sq6vb   1/1     Running   0          22h


$ kubectl cordon minikube
node/minikube cordoned

$ kubectl get node
NAME       STATUS                     ROLES    AGE     VERSION
minikube   Ready,SchedulingDisabled   master   6d18h   v1.17.0
</code></pre><p>=> minikube node에 cordon 설정하자 SchedulingDisabled 상태가 됨</p><ul><li>scale 해보자</li></ul><pre><code>$ kubectl scale deployment.apps/redis-deployment2 --replicas=4
deployment.apps/redis-deployment2 scaled

$ kubectl get deploy,pod
NAME                                READY   UP-TO-DATE   AVAILABLE   AGE
deployment.apps/redis-deployment2   2/4     4            2           22h

NAME                                     READY   STATUS    RESTARTS   AGE
pod/redis-deployment2-6bcb64f4d4-h6vsl   0/1     Pending   0          6s
pod/redis-deployment2-6bcb64f4d4-lb68q   0/1     Pending   0          6s
pod/redis-deployment2-6bcb64f4d4-lq5pc   1/1     Running   0          22h
pod/redis-deployment2-6bcb64f4d4-sq6vb   1/1     Running   0          22h
</code></pre><p>=> 기존에 떠있던 pod는 상관없지만 새로 추가로 띄운 2대의 pod은 pending 상태임, node가 단 하나인데 그걸 cordon해버렸으니..</p><ul><li>cordon 해제하면?</li></ul><pre><code>$ kubectl uncordon minikube
node/minikube uncordoned

$ kubectl get deploy,pod
NAME                                READY   UP-TO-DATE   AVAILABLE   AGE
deployment.apps/redis-deployment2   2/4     4            2           22h
deployment.apps/testnet             1/1     1            1           5d18h

NAME                                     READY   STATUS              RESTARTS   AGE
pod/redis-deployment2-6bcb64f4d4-h6vsl   0/1     ContainerCreating   0          97s
pod/redis-deployment2-6bcb64f4d4-lb68q   0/1     ContainerCreating   0          97s
pod/redis-deployment2-6bcb64f4d4-lq5pc   1/1     Running             0          22h
pod/redis-deployment2-6bcb64f4d4-sq6vb   1/1     Running             0          22h
</code></pre><p>=> uncordon 하면 pending상태였던 pod이 다시 생성됨</p><h3 id=drain>drain<a hidden class=anchor aria-hidden=true href=#drain>#</a></h3><p>drain 기능은 특정 node의 pod들을 다른 node로 이동시키는 기능으로 drain 수행 시<br>해당 Node에 pod scheduling을 막고, 실행중이던 pod들을 삭제한다. 이 때 pod에서 수행되던 작업들이 정리될 때 까지 기다린 후 삭제한다. (graceful)</p><ul><li><p>drain 안되는 세가지 경우</p><ul><li><p>파드가 emptyDir을 사용하여 local data를 저장하는 경우<br>=> emptyDir를 사용하여 local data를 저장하는 파드가 해당 워커 노드에 있는 경우, 이 파드를 삭제 시 해당 데이터 또한 삭제되므로 수행되지 않습니다. 해당 파드가 제거되어도 문제가 없는 경우에는 &ndash;delete-local-data 플래그를 drain 명령어에 추가하여 수행합니다.</p></li><li><p>해당 워커 노드에 데몬셋(daemonset)이 구동되고 있는 경우<br>=> 데몬셋에 속한 파드가 해당 워커 노드에 구동되고 있는 경우, kubectl drain 명령이 수행되지 않습니다. 데몬셋 컨트롤러는 노드가 unschedulable 상태에 있더라도 이를 무시하고 해당 노드에 파드를 스케줄하여 배치할 수 있습니다. 데몬셋에 속한 파드가 있는 경우에는, &ndash;ignore-daemonsets 플래그를 추가하여 해당 파드를 축출 대상에서 제외할 수 있습니다.</p></li><li><p>Kubernetes의 컨트롤러에서 관리되지 않는 파드가 구동되고 있는 경우<br>=> Kubernetes에서는 Deployment, Statefulset, DaemonSet, ReplicaSet, Job과 같은 컨트롤러가 관리하지 않는 파드가 해당 워커 노드 상에 있는 경우, kubectl drain 명령어는 이를 보호하기 위해서 동작하지 않습니다. &ndash;force 플래그를 추가하여 kubectl drain 명령어를 실행하는 경우, 이러한 파드는 클러스터에서 제거되며 재스케줄링되지 않습니다.</p></li></ul></li><li><p>drain 해보자</p></li></ul><pre><code>$ kubectl drain minikube
node/minikube already cordoned
error: unable to drain node &quot;minikube&quot;, aborting command...

There are pending nodes to be drained:
 minikube
cannot delete DaemonSet-managed Pods (use --ignore-daemonsets to ignore): kube-system/kube-proxy-vxf7k
cannot delete Pods not managed by ReplicationController, ReplicaSet, Job, DaemonSet or StatefulSet (use --force to override): kube-system/storage-provisioner
cannot delete Pods with local storage (use --delete-local-data to override): kubernetes-dashboard/dashboard-metrics-scraper-7b64584c5c-mn29t, kubernetes-dashboard/kubernetes-dashboard-79d9cd965-rsbzn
</code></pre><p>=> 뭔가 demonset, 혹은 emptyDir을 사용하는 Pod 들이 있다며 drain이 안된다는 에러가 떴다. 처음보는 Pod들인데 그 내가 사용하는 namespace의 Pod들이 아니기 때문이다.</p><pre><code>$ kubectl get deploy,pod --all-namespaces
NAMESPACE              NAME                                        READY   UP-TO-DATE   AVAILABLE   AGE
default                deployment.apps/redis-deployment2           4/4     4            4           26h
default                deployment.apps/testnet                     1/1     1            1           5d23h
kube-system            deployment.apps/coredns                     2/2     2            2           6d23h
kubernetes-dashboard   deployment.apps/dashboard-metrics-scraper   1/1     1            1           6d23h
kubernetes-dashboard   deployment.apps/kubernetes-dashboard        1/1     1            1           6d23h

NAMESPACE              NAME                                             READY   STATUS    RESTARTS   AGE
default                pod/redis-deployment2-6bcb64f4d4-h6vsl           1/1     Running   0          4h34m
default                pod/redis-deployment2-6bcb64f4d4-lb68q           1/1     Running   0          4h34m
default                pod/redis-deployment2-6bcb64f4d4-lq5pc           1/1     Running   0          26h
default                pod/redis-deployment2-6bcb64f4d4-sq6vb           1/1     Running   0          26h
default                pod/testnet-5f694fd785-lb5x8                     1/1     Running   1          5d23h
kube-system            pod/coredns-6955765f44-k6cv4                     1/1     Running   0          6d23h
kube-system            pod/coredns-6955765f44-mg7xp                     1/1     Running   0          6d23h
kube-system            pod/etcd-minikube                                1/1     Running   0          6d23h
kube-system            pod/kube-addon-manager-minikube                  1/1     Running   0          6d23h
kube-system            pod/kube-apiserver-minikube                      1/1     Running   0          6d23h
kube-system            pod/kube-controller-manager-minikube             1/1     Running   5          6d23h
kube-system            pod/kube-proxy-vxf7k                             1/1     Running   0          6d23h
kube-system            pod/kube-scheduler-minikube                      1/1     Running   4          6d23h
kube-system            pod/storage-provisioner                          1/1     Running   0          6d23h
kubernetes-dashboard   pod/dashboard-metrics-scraper-7b64584c5c-mn29t   1/1     Running   0          6d23h
kubernetes-dashboard   pod/kubernetes-dashboard-79d9cd965-rsbzn         1/1     Running   0          6d23h
</code></pre><ul><li>옵션 추가하여 다시 drain 해보자</li></ul><pre><code>$ kubectl drain minikube --ignore-daemonsets=true --force --delete-local-data
node/minikube already cordoned
WARNING: deleting Pods not managed by ReplicationController, ReplicaSet, Job, DaemonSet or StatefulSet: kube-system/storage-provisioner; ignoring DaemonSet-managed Pods: kube-system/kube-proxy-vxf7k
evicting pod &quot;testnet-5f694fd785-lb5x8&quot;
evicting pod &quot;coredns-6955765f44-mg7xp&quot;
evicting pod &quot;redis-deployment2-6bcb64f4d4-lb68q&quot;
evicting pod &quot;storage-provisioner&quot;
evicting pod &quot;kubernetes-dashboard-79d9cd965-rsbzn&quot;
evicting pod &quot;coredns-6955765f44-k6cv4&quot;
evicting pod &quot;redis-deployment2-6bcb64f4d4-h6vsl&quot;
evicting pod &quot;redis-deployment2-6bcb64f4d4-lq5pc&quot;
evicting pod &quot;redis-deployment2-6bcb64f4d4-sq6vb&quot;
evicting pod &quot;dashboard-metrics-scraper-7b64584c5c-mn29t&quot;

pod/dashboard-metrics-scraper-7b64584c5c-mn29t evicted
pod/redis-deployment2-6bcb64f4d4-sq6vb evicted
pod/redis-deployment2-6bcb64f4d4-h6vsl evicted
pod/kubernetes-dashboard-79d9cd965-rsbzn evicted
pod/testnet-5f694fd785-lb5x8 evicted
pod/storage-provisioner evicted
pod/redis-deployment2-6bcb64f4d4-lb68q evicted
pod/coredns-6955765f44-k6cv4 evicted
pod/redis-deployment2-6bcb64f4d4-lq5pc evicted
pod/coredns-6955765f44-mg7xp evicted
node/minikube evicted
</code></pre><p>=> minikube node 안에 있던 pod들이 쫓겨났다</p><ul><li>다시 조회해보자</li></ul><pre><code>$ kubectl get deploy,pod --all-namespaces
NAMESPACE              NAME                                        READY   UP-TO-DATE   AVAILABLE   AGE
default                deployment.apps/redis-deployment2           0/4     4            0           27h
default                deployment.apps/testnet                     0/1     1            0           5d23h
kube-system            deployment.apps/coredns                     0/2     2            0           6d23h
kubernetes-dashboard   deployment.apps/dashboard-metrics-scraper   0/1     1            0           6d23h
kubernetes-dashboard   deployment.apps/kubernetes-dashboard        0/1     1            0           6d23h

NAMESPACE              NAME                                             READY   STATUS    RESTARTS   AGE
default                pod/redis-deployment2-6bcb64f4d4-8rzpc           0/1     Pending   0          15m
default                pod/redis-deployment2-6bcb64f4d4-j46d7           0/1     Pending   0          15m
default                pod/redis-deployment2-6bcb64f4d4-psksx           0/1     Pending   0          15m
default                pod/redis-deployment2-6bcb64f4d4-r64b7           0/1     Pending   0          15m
default                pod/testnet-5f694fd785-dv46g                     0/1     Pending   0          15m
kube-system            pod/coredns-6955765f44-2pfdc                     0/1     Pending   0          15m
kube-system            pod/coredns-6955765f44-59cp5                     0/1     Pending   0          15m
kube-system            pod/etcd-minikube                                1/1     Running   0          6d23h
kube-system            pod/kube-addon-manager-minikube                  1/1     Running   0          6d23h
kube-system            pod/kube-apiserver-minikube                      1/1     Running   0          6d23h
kube-system            pod/kube-controller-manager-minikube             1/1     Running   5          6d23h
kube-system            pod/kube-proxy-vxf7k                             1/1     Running   0          6d23h
kube-system            pod/kube-scheduler-minikube                      1/1     Running   4          6d23h
kube-system            pod/storage-provisioner                          0/1     Pending   0          15m
kubernetes-dashboard   pod/dashboard-metrics-scraper-7b64584c5c-6dn8b   0/1     Pending   0          15m
kubernetes-dashboard   pod/kubernetes-dashboard-79d9cd965-25zcr         0/1     Pending   0          15m
</code></pre><p>=> node 가 minikube 하나라서 옮겨갈 곳이 없으니 전부 pending 상태임<br>그리고 마스터노드의 kube-apiserver를 이용해서 생성된 것이 아닌 kubelet이 직접 실행한 static pod들은 상관없이 running 상태</p><ul><li>drain 설정 해제</li></ul><pre><code>$ kubectl uncordon minikube
node/minikube uncordoned

$ kubectl get deploy,pod --all-namespaces
NAMESPACE              NAME                                        READY   UP-TO-DATE   AVAILABLE   AGE
default                deployment.apps/redis-deployment2           4/4     4            4           27h
default                deployment.apps/testnet                     1/1     1            1           5d23h
kube-system            deployment.apps/coredns                     2/2     2            2           6d23h
kubernetes-dashboard   deployment.apps/dashboard-metrics-scraper   1/1     1            1           6d23h
kubernetes-dashboard   deployment.apps/kubernetes-dashboard        1/1     1            1           6d23h

NAMESPACE              NAME                                             READY   STATUS    RESTARTS   AGE
default                pod/redis-deployment2-6bcb64f4d4-8rzpc           1/1     Running   0          19m
default                pod/redis-deployment2-6bcb64f4d4-j46d7           1/1     Running   0          19m
default                pod/redis-deployment2-6bcb64f4d4-psksx           1/1     Running   0          19m
default                pod/redis-deployment2-6bcb64f4d4-r64b7           1/1     Running   0          19m
default                pod/testnet-5f694fd785-dv46g                     1/1     Running   0          19m
kube-system            pod/coredns-6955765f44-2pfdc                     1/1     Running   0          19m
kube-system            pod/coredns-6955765f44-59cp5                     1/1     Running   0          19m
kube-system            pod/etcd-minikube                                1/1     Running   0          6d23h
kube-system            pod/kube-addon-manager-minikube                  1/1     Running   0          6d23h
kube-system            pod/kube-apiserver-minikube                      1/1     Running   0          6d23h
kube-system            pod/kube-controller-manager-minikube             1/1     Running   5          6d23h
kube-system            pod/kube-proxy-vxf7k                             1/1     Running   0          6d23h
kube-system            pod/kube-scheduler-minikube                      1/1     Running   4          6d23h
kube-system            pod/storage-provisioner                          1/1     Running   0          19m
kubernetes-dashboard   pod/dashboard-metrics-scraper-7b64584c5c-6dn8b   1/1     Running   0          19m
kubernetes-dashboard   pod/kubernetes-dashboard-79d9cd965-25zcr         1/1     Running   0          19m
</code></pre></div><footer class=post-footer><ul class=post-tags><li><a href=/tags/kubernetes/>kubernetes</a></li></ul></footer><div id=disqus_thread></div><script type=text/javascript>(function(){if(window.location.hostname=="localhost")
return;var dsq=document.createElement('script');dsq.type='text/javascript';dsq.async=true;var disqus_shortname='kimdubia';dsq.src='//'+disqus_shortname+'.disqus.com/embed.js';(document.getElementsByTagName('head')[0]||document.getElementsByTagName('body')[0]).appendChild(dsq);})();</script><noscript>Please enable JavaScript to view the <a href=https://disqus.com/?ref_noscript>comments powered by Disqus.</a></noscript><a href=https://disqus.com/ class=dsq-brlink>comments powered by <span class=logo-disqus>Disqus</span></a></article></main><footer class=footer><span>&copy; 2022 <a href>kimDuBiA</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://git.io/hugopapermod rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg></a><script>let menu=document.getElementById('menu')
menu.scrollLeft=localStorage.getItem("menu-scroll-position");menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft);}
document.querySelectorAll('a[href^="#"]').forEach(anchor=>{anchor.addEventListener("click",function(e){e.preventDefault();var id=this.getAttribute("href").substr(1);if(!window.matchMedia('(prefers-reduced-motion: reduce)').matches){document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({behavior:"smooth"});}else{document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();}
if(id==="top"){history.replaceState(null,null," ");}else{history.pushState(null,null,`#${id}`);}});});</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){if(document.body.scrollTop>800||document.documentElement.scrollTop>800){mybutton.style.visibility="visible";mybutton.style.opacity="1";}else{mybutton.style.visibility="hidden";mybutton.style.opacity="0";}};</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{if(document.body.className.includes("dark")){document.body.classList.remove('dark');localStorage.setItem("pref-theme",'light');}else{document.body.classList.add('dark');localStorage.setItem("pref-theme",'dark');}})</script><script>document.querySelectorAll('pre > code').forEach((codeblock)=>{const container=codeblock.parentNode.parentNode;const copybutton=document.createElement('button');copybutton.classList.add('copy-code');copybutton.innerText='copy';function copyingDone(){copybutton.innerText='copied!';setTimeout(()=>{copybutton.innerText='copy';},2000);}
copybutton.addEventListener('click',(cb)=>{if('clipboard'in navigator){navigator.clipboard.writeText(codeblock.textContent);copyingDone();return;}
const range=document.createRange();range.selectNodeContents(codeblock);const selection=window.getSelection();selection.removeAllRanges();selection.addRange(range);try{document.execCommand('copy');copyingDone();}catch(e){};selection.removeRange(range);});if(container.classList.contains("highlight")){container.appendChild(copybutton);}else if(container.parentNode.firstChild==container){}else if(codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"){codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(copybutton);}else{codeblock.parentNode.appendChild(copybutton);}});</script></body></html>
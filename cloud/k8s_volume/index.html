<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>kubernetes Volume | kimDuBiA</title><meta name=keywords content="kubernetes"><meta name=description content="혼자 쿠버네티스 정리하기 위한 글, 오늘은 volume 편
여태 생성했던 Pod들은 stateless container를 사용하고 있었다. 그래서 Pod나 Node가 재기동되면 그 데이터가 사라지는 단점이 있었다.
만약 제공해야하는 서비스에서 이런 경우에도 데이터를 계속 보존해야한다면 kubernetes에서는 Volume을 사용해야한다.
volume emptyDir Pod가 실행되는 host의 disk를 Contatiner의 volume으로 할당하는 기능,
Container가 재기동 되어도 데이터는 보존되지만 Pod가 종료되면 emptyDir에 할당했던 volume 내 데이터도 사라진다.
이 점이 앞서 살펴봤던 kubectl drain node 수행 시 emptyDir 사용하는 Pod이 있는 경우 에러가 발생하는 이유인듯"><meta name=author content="kimdubi"><link rel=canonical href=/cloud/k8s_volume/><meta name=google-site-verification content="XYZabc"><meta name=yandex-verification content="XYZabc"><meta name=msvalidate.01 content="XYZabc"><link crossorigin=anonymous href=/assets/css/stylesheet.min.2dbef8664bbfb3e83a0a44fd4a8fc5010240dbcd1dbc1400753b928b497b8f5e.css integrity="sha256-Lb74Zku/s+g6CkT9So/FAQJA280dvBQAdTuSi0l7j14=" rel="preload stylesheet" as=style><script defer crossorigin=anonymous src=/assets/js/highlight.min.27cd435cc9ed6abb4b496581b151804f79f366c412620272bb94e2f5f598ebcc.js integrity="sha256-J81DXMntartLSWWBsVGAT3nzZsQSYgJyu5Ti9fWY68w=" onload=hljs.initHighlightingOnLoad();></script><link rel=icon href=%3Clink%20/%20abs%20url%3E><link rel=icon type=image/png sizes=16x16 href=%3Clink%20/%20abs%20url%3E><link rel=icon type=image/png sizes=32x32 href=%3Clink%20/%20abs%20url%3E><link rel=apple-touch-icon href=%3Clink%20/%20abs%20url%3E><link rel=mask-icon href=%3Clink%20/%20abs%20url%3E><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><meta name=generator content="Hugo 0.80.0"><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme: rgb(29, 30, 32);--entry: rgb(46, 46, 51);--primary: rgb(218, 218, 219);--secondary: rgb(155, 156, 157);--tertiary: rgb(65, 66, 68);--content: rgb(196, 196, 197);--hljs-bg: rgb(46, 46, 51);--code-bg: rgb(55, 56, 62);--border: rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><script type=application/javascript>var doNotTrack=false;if(!doNotTrack){(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');ga('create','UA-123-45','auto');ga('send','pageview');}</script><meta property="og:title" content="kubernetes Volume"><meta property="og:description" content="혼자 쿠버네티스 정리하기 위한 글, 오늘은 volume 편
여태 생성했던 Pod들은 stateless container를 사용하고 있었다. 그래서 Pod나 Node가 재기동되면 그 데이터가 사라지는 단점이 있었다.
만약 제공해야하는 서비스에서 이런 경우에도 데이터를 계속 보존해야한다면 kubernetes에서는 Volume을 사용해야한다.
volume emptyDir Pod가 실행되는 host의 disk를 Contatiner의 volume으로 할당하는 기능,
Container가 재기동 되어도 데이터는 보존되지만 Pod가 종료되면 emptyDir에 할당했던 volume 내 데이터도 사라진다.
이 점이 앞서 살펴봤던 kubectl drain node 수행 시 emptyDir 사용하는 Pod이 있는 경우 에러가 발생하는 이유인듯"><meta property="og:type" content="article"><meta property="og:url" content="/cloud/k8s_volume/"><meta property="og:image" content="%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta property="article:section" content="cloud"><meta property="article:published_time" content="2021-10-06T09:22:43+09:00"><meta property="article:modified_time" content="2021-10-06T09:22:43+09:00"><meta property="og:site_name" content="kimDuBiA"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta name=twitter:title content="kubernetes Volume"><meta name=twitter:description content="혼자 쿠버네티스 정리하기 위한 글, 오늘은 volume 편
여태 생성했던 Pod들은 stateless container를 사용하고 있었다. 그래서 Pod나 Node가 재기동되면 그 데이터가 사라지는 단점이 있었다.
만약 제공해야하는 서비스에서 이런 경우에도 데이터를 계속 보존해야한다면 kubernetes에서는 Volume을 사용해야한다.
volume emptyDir Pod가 실행되는 host의 disk를 Contatiner의 volume으로 할당하는 기능,
Container가 재기동 되어도 데이터는 보존되지만 Pod가 종료되면 emptyDir에 할당했던 volume 내 데이터도 사라진다.
이 점이 앞서 살펴봤던 kubectl drain node 수행 시 emptyDir 사용하는 Pod이 있는 경우 에러가 발생하는 이유인듯"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":2,"name":"Clouds","item":"/cloud/"},{"@type":"ListItem","position":3,"name":"kubernetes Volume","item":"/cloud/k8s_volume/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"kubernetes Volume","name":"kubernetes Volume","description":"혼자 쿠버네티스 정리하기 위한 글, 오늘은 volume 편\n여태 생성했던 Pod들은 stateless container를 사용하고 있었다. 그래서 Pod나 Node가 재기동되면 그 데이터가 사라지는 단점이 있었다.\n만약 제공해야하는 서비스에서 이런 경우에도 데이터를 계속 보존해야한다면 kubernetes에서는 Volume을 사용해야한다.\nvolume emptyDir Pod가 실행되는 host의 disk를 Contatiner의 volume으로 할당하는 기능,\nContainer가 재기동 되어도 데이터는 보존되지만 Pod가 종료되면 emptyDir에 할당했던 volume 내 데이터도 사라진다.\n이 점이 앞서 살펴봤던 kubectl drain node 수행 시 emptyDir 사용하는 Pod이 있는 경우 에러가 발생하는 이유인듯","keywords":["kubernetes"],"articleBody":" 혼자 쿠버네티스 정리하기 위한 글, 오늘은 volume 편\n여태 생성했던 Pod들은 stateless container를 사용하고 있었다. 그래서 Pod나 Node가 재기동되면 그 데이터가 사라지는 단점이 있었다.\n만약 제공해야하는 서비스에서 이런 경우에도 데이터를 계속 보존해야한다면 kubernetes에서는 Volume을 사용해야한다.\nvolume emptyDir Pod가 실행되는 host의 disk를 Contatiner의 volume으로 할당하는 기능,\nContainer가 재기동 되어도 데이터는 보존되지만 Pod가 종료되면 emptyDir에 할당했던 volume 내 데이터도 사라진다.\n이 점이 앞서 살펴봤던 kubectl drain node 수행 시 emptyDir 사용하는 Pod이 있는 경우 에러가 발생하는 이유인듯\napiVersion: v1 kind: Pod metadata: name: emptydir-test labels: app: emptydir-test spec: containers: - name: nginx image: nginx volumeMounts: - mountPath: /emptydir name: emptydir-volume volumes: - name: emptydir-volume emptyDir: {}  = .spec.contatiners.volumes[] 에서 사용햐려는 볼륨을 먼저 생성한다.\nemptydir-volume이라는 이름의 emptyDir을 생성하고 volumeMounts 에서 이 volume을 사용하겠다고 지정 후\n( .spec.containers.volumes[].name = .spec.containers.volumeMounts[].name 으로 매핑 )\n.mountPath 필드 값으로 container의 /emptydir 디렉토리로 mount\nhostPath Pod이 실행되는 host의 파일이나 디렉토리를 Pod에 mount하는 기능\nemptyDir과는 달리 Pod이 재기동되어도 host에 데이터가 남음\napiVersion: v1 kind: Pod metadata: name: hostpath-test labels: app: hostpath-test spec: containers: - name: nginx image: nginx volumeMounts: - mountPath: /hostpath-volume name: hostpath-volume volumes: - name: hostpath-volume hostPath: path: /Users/nhn/Documents/kubernetes/volume type: Directory  PersistentVolume \u0026 PersistentVolumeClaim 앞서 봤던 volume은 volume을 Pod에 직접 할당하는 방식이다.\n그렇기 때문에 만약 Pod가 사라지면 직접 할당된 volume도 사라지고 volume에 변경사항이 생기면 (ex. voulme type)\nPod의 volume을 일일이 바꿔줘야 하는 불편사항이 있다.\n이 구조를 Pod - PVC - PV 로 변경하게 되면 Pod는 PVC를 거쳐서 volume을 사용하게 되기 때문에 어떤 스토리지를 사용하는지 신경 쓰지 않아도 되고\nPVC 에서 PV만 새로 변경해주면 되기 때문에 상황에 맞게 유연한 사용이 가능하다.\nPV ( PersistentVolume ) 가상의 volume 객체로 kubernetes cluster에서 Pod와는 별개 된 자원으로서 관리한다.\n별도의 생명주기가 있으며 PVC를 통해 PV 할당 요청을 받으면 사용하고 싶은 용량, 읽기/쓰기 모드 등에 맞게 PV를 provisiong 한다.\n위는 static provisiong의 방식을 나타내는데 PV와 PVC는 아래와 같은 생명 주기를 갖는다.\n provisioing : PV를 생성하는 단계로 미리 만들어 놓는 static, PVC로 부터 요청이 있을 때마다 생성하는 dynamic 방식이 있다. binding : Provisioning으로 생성한 PV를 PVC와 연결하는 단계, PVC에서 요청한 스펙의 PV를 매핑한다. PV와 PVC는 1:1 관계 using: PVC는 Pod에 연결되고, Pod는 PVC를 volume ,즉 PVC로 인식해서 사용하는 단계 reclaiming: 사용이 끝난 PVC는 삭제하고 PV를 초기화 하는 과정 pv_test.yaml  apiVersion: v1 kind: PersistentVolume metadata: name: pv-test labels: storage: prod spec: capacity: storage: 1Gi volumeMode: Filesystem accessModes: - ReadWriteOnce storageClassName: test persistentVolumeReclaimPolicy: Delete hostPath: path: /Users/nhn/Documents/kubernetes/volume/test/pv-test = volume plugin=hostPath 방식으로 1GB 짜리 PV 생성\nPVC ( PersistentVolumeClaim ) Pod가 자신이 사용하는 스토리지를 신경쓸 필요 없이 PVC를 통해 사용하고 싶은 스펙의 PV를 PVC에 요청하면 PVC가 그 스펙에 맞는 PV를 생성하고 자신과 매핑시킴.\nPod는 결국 PVC를 Volume으로 인식하여 사용하게 됨\n pvc_test.yaml  apiVersion: v1 kind: PersistentVolumeClaim metadata: name: pvc-test spec: accessModes: - ReadWriteOnce volumeMode: Filesystem resources: requests: storage: 1Gi storageClassName: test selector: matchLabels: storage: prod = .spec.resources.requests 필드를 통해 필요로 하는 자원을 요청한다.\n.spec.selector 를 이용하여 labels로 PV와 매핑할 수 있음\n$ kubectl get pv,pvc NAME CAPACITY ACCESS MODES RECLAIM POLICY STATUS CLAIM STORAGECLASS REASON AGE persistentvolume/pv-test 1Gi RWO Delete Bound default/pvc-test test 6m47s NAME STATUS VOLUME CAPACITY ACCESS MODES STORAGECLASS AGE persistentvolumeclaim/pvc-test Bound pv-test 1Gi RWO test 7s  = pvc-test PVC가 pv-test PV와 연결된 것을 확인\n 매핑되는 PV가 없을 때  $ kubectl get pv,pvc NAME CAPACITY ACCESS MODES RECLAIM POLICY STATUS CLAIM STORAGECLASS REASON AGE persistentvolume/pv-test 1Gi RWO Delete Available test 74s NAME STATUS VOLUME CAPACITY ACCESS MODES STORAGECLASS AGE persistentvolumeclaim/pvc-test Pending manual 63s = PVC 에서 요청한 storageclass를 사용하는 PV가 없어서 PVC가 PV를 매핑하지 못하고 pending 상태임\n 매핑되는 PV를 생성하고 다시 조회해보자  $ kubectl get pv,pvc NAME CAPACITY ACCESS MODES RECLAIM POLICY STATUS CLAIM STORAGECLASS REASON AGE persistentvolume/pv-test 1Gi RWO Delete Bound default/pvc-test manual 2m53s NAME STATUS VOLUME CAPACITY ACCESS MODES STORAGECLASS AGE persistentvolumeclaim/pvc-test Bound pv-test 1Gi RWO manual 2m42s PVC를 사용하는 Pod를 생성해보자 --- apiVersion: apps/v1 kind: Deployment metadata: name: nginx-pvc-test labels: app: nginx-pvc-test spec: replicas: 2 selector: matchLabels: app: nginx template: metadata: name: nginx labels: app: nginx spec: containers: - name: nginx image: nginx ports: - containerPort: 80 volumeMounts: - name: pod-pvc-test mountPath: /pv-test volumes: - name: pod-pvc-test persistentVolumeClaim: claimName: pvc-test  = .spec.template.spec.volumes[].name 으로 사용할 volume을 선언하는데\n.spec.template.spec.volumes[].persistentVolumeClaim.cclaimName으로 이전에 생성해놓은 pvc-test PVC를 설정한다.\n.spec.template.specc.containers.volumeMounts[].name에서 pvc-test volume을 conatiner의 /pv-test에 mount 한다고 설정한다.\n그리고 이 pvc-test PVC는 pv-test 와 매핑되는데 pv-test 는 이전에 hostPath로 host의 /Users/nhn/Documents/kubernetes/volume/test/pv-test 디렉토리에 마운트됨\n$ kubectl describe pod/nginx-pvc-test-5d55669b9-vm8ml Volumes: pod-pvc-test: Type: PersistentVolumeClaim (a reference to a PersistentVolumeClaim in the same namespace) ClaimName: pvc-test $ kubectl describe persistentvolumeclaim/pvc-test Volume: pv-test Mounted By: nginx-pvc-test-5d55669b9-nkq68 nginx-pvc-test-5d55669b9-vm8ml $ kubectl describe persistentvolume/pv-test Source: Type: HostPath (bare host directory volume) Path: /Users/nhn/Documents/kubernetes/volume/test/pv-test  ","wordCount":"734","inLanguage":"en","datePublished":"2021-10-06T09:22:43+09:00","dateModified":"2021-10-06T09:22:43+09:00","author":{"@type":"Person","name":"kimdubi"},"mainEntityOfPage":{"@type":"WebPage","@id":"/cloud/k8s_volume/"},"publisher":{"@type":"Organization","name":"kimDuBiA","logo":{"@type":"ImageObject","url":"%3Clink%20/%20abs%20url%3E"}}}</script></head><body id=top><script>if(localStorage.getItem("pref-theme")==="dark"){document.body.classList.add('dark');}else if(localStorage.getItem("pref-theme")==="light"){document.body.classList.remove('dark')}else if(window.matchMedia('(prefers-color-scheme: dark)').matches){document.body.classList.add('dark');}</script><header class=header><nav class=nav><div class=logo><a href accesskey=h title="Hi (Alt + H)">Hi</a>
<span class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></span></div><ul id=menu><li><a href=/ title=Home><span>Home</span></a></li><li><a href=/categories/ title=Categories><span>Categories</span></a></li><li><a href=/tags/ title=tags><span>tags</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href>Home</a>&nbsp;»&nbsp;<a href=/cloud/>Clouds</a></div><h1 class=post-title>kubernetes Volume</h1><div class=post-meta>October 6, 2021&nbsp;·&nbsp;4 min&nbsp;·&nbsp;kimdubi</div></header><div class=toc><details><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><ul><li><a href=#volume aria-label=volume>volume</a><ul><li><a href=#emptydir aria-label=emptyDir>emptyDir</a></li><li><a href=#hostpath aria-label=hostPath>hostPath</a></li></ul></li><li><a href=#persistentvolume--persistentvolumeclaim aria-label="PersistentVolume &amp;amp; PersistentVolumeClaim">PersistentVolume & PersistentVolumeClaim</a><ul><li><a href=#pv--persistentvolume- aria-label="PV ( PersistentVolume )">PV ( PersistentVolume )</a></li><li><a href=#pvc--persistentvolumeclaim- aria-label="PVC ( PersistentVolumeClaim )">PVC ( PersistentVolumeClaim )</a></li><li><a href=#pvc%eb%a5%bc-%ec%82%ac%ec%9a%a9%ed%95%98%eb%8a%94-pod%eb%a5%bc-%ec%83%9d%ec%84%b1%ed%95%b4%eb%b3%b4%ec%9e%90 aria-label="PVC를 사용하는 Pod를 생성해보자">PVC를 사용하는 Pod를 생성해보자</a></li></ul></li></ul></div></details></div><div class=post-content><hr><p>혼자 쿠버네티스 정리하기 위한 글, 오늘은 volume 편</p><p>여태 생성했던 Pod들은 stateless container를 사용하고 있었다. 그래서 Pod나 Node가 재기동되면 그 데이터가 사라지는 단점이 있었다.<br>만약 제공해야하는 서비스에서 이런 경우에도 데이터를 계속 보존해야한다면 kubernetes에서는 Volume을 사용해야한다.</p><h2 id=volume>volume<a hidden class=anchor aria-hidden=true href=#volume>#</a></h2><h3 id=emptydir>emptyDir<a hidden class=anchor aria-hidden=true href=#emptydir>#</a></h3><p>Pod가 실행되는 host의 disk를 Contatiner의 volume으로 할당하는 기능,<br>Container가 재기동 되어도 데이터는 보존되지만 Pod가 종료되면 emptyDir에 할당했던 volume 내 데이터도 사라진다.<br>이 점이 앞서 살펴봤던 kubectl drain node 수행 시 emptyDir 사용하는 Pod이 있는 경우 에러가 발생하는 이유인듯</p><pre><code>apiVersion: v1 
kind: Pod 
metadata: 
  name: emptydir-test 
  labels:
    app: emptydir-test 
spec:
  containers:
  - name: nginx
    image: nginx 
    volumeMounts:
    - mountPath: /emptydir 
      name: emptydir-volume 
    volumes:
    - name: emptydir-volume 
      emptyDir: {}
</code></pre><p>=> .spec.contatiners.volumes[] 에서 사용햐려는 볼륨을 먼저 생성한다.<br>emptydir-volume이라는 이름의 emptyDir을 생성하고 volumeMounts 에서 이 volume을 사용하겠다고 지정 후<br>( .spec.containers.volumes[].name => .spec.containers.volumeMounts[].name 으로 매핑 )<br>.mountPath 필드 값으로 container의 /emptydir 디렉토리로 mount</p><h3 id=hostpath>hostPath<a hidden class=anchor aria-hidden=true href=#hostpath>#</a></h3><p>Pod이 실행되는 host의 파일이나 디렉토리를 Pod에 mount하는 기능<br>emptyDir과는 달리 Pod이 재기동되어도 host에 데이터가 남음</p><pre><code>apiVersion: v1
kind: Pod
metadata:
  name: hostpath-test
  labels:
    app: hostpath-test
spec:
  containers:
  - name: nginx
    image: nginx
    volumeMounts:
    - mountPath: /hostpath-volume
      name: hostpath-volume
  volumes:
  - name: hostpath-volume
    hostPath:
      path: /Users/nhn/Documents/kubernetes/volume
      type: Directory
</code></pre><h2 id=persistentvolume--persistentvolumeclaim>PersistentVolume & PersistentVolumeClaim<a hidden class=anchor aria-hidden=true href=#persistentvolume--persistentvolumeclaim>#</a></h2><p>앞서 봤던 volume은 volume을 Pod에 직접 할당하는 방식이다.<br>그렇기 때문에 만약 Pod가 사라지면 직접 할당된 volume도 사라지고 volume에 변경사항이 생기면 (ex. voulme type)<br>Pod의 volume을 일일이 바꿔줘야 하는 불편사항이 있다.</p><p>이 구조를 Pod -> PVC -> PV 로 변경하게 되면 Pod는 PVC를 거쳐서 volume을 사용하게 되기 때문에 어떤 스토리지를 사용하는지 신경 쓰지 않아도 되고<br>PVC 에서 PV만 새로 변경해주면 되기 때문에 상황에 맞게 유연한 사용이 가능하다.</p><h3 id=pv--persistentvolume->PV ( PersistentVolume )<a hidden class=anchor aria-hidden=true href=#pv--persistentvolume->#</a></h3><p>가상의 volume 객체로 kubernetes cluster에서 Pod와는 별개 된 자원으로서 관리한다.<br>별도의 생명주기가 있으며 PVC를 통해 PV 할당 요청을 받으면 사용하고 싶은 용량, 읽기/쓰기 모드 등에 맞게 PV를 provisiong 한다.</p><p><img loading=lazy src=https://raw.githubusercontent.com/kimdubi/kimdubi.github.io/master/images/cloud/pv_static.png alt><br>위는 static provisiong의 방식을 나타내는데 PV와 PVC는 아래와 같은 생명 주기를 갖는다.</p><ul><li>provisioing : PV를 생성하는 단계로 미리 만들어 놓는 static, PVC로 부터 요청이 있을 때마다 생성하는 dynamic 방식이 있다.</li><li>binding : Provisioning으로 생성한 PV를 PVC와 연결하는 단계, PVC에서 요청한 스펙의 PV를 매핑한다. PV와 PVC는 1:1 관계</li><li>using: PVC는 Pod에 연결되고, Pod는 PVC를 volume ,즉 PVC로 인식해서 사용하는 단계</li><li>reclaiming: 사용이 끝난 PVC는 삭제하고 PV를 초기화 하는 과정</li><li>pv_test.yaml</li></ul><pre><code>apiVersion: v1
kind: PersistentVolume 
metadata: 
  name: pv-test 
  labels:
    storage: prod
spec:
  capacity:
    storage: 1Gi
  volumeMode: Filesystem
  accessModes: 
  - ReadWriteOnce  
  storageClassName: test
  persistentVolumeReclaimPolicy: Delete
  hostPath:
    path: /Users/nhn/Documents/kubernetes/volume/test/pv-test
</code></pre><p>=> volume plugin=hostPath 방식으로 1GB 짜리 PV 생성</p><h3 id=pvc--persistentvolumeclaim->PVC ( PersistentVolumeClaim )<a hidden class=anchor aria-hidden=true href=#pvc--persistentvolumeclaim->#</a></h3><p>Pod가 자신이 사용하는 스토리지를 신경쓸 필요 없이 PVC를 통해 사용하고 싶은 스펙의 PV를 PVC에 요청하면 PVC가 그 스펙에 맞는 PV를 생성하고 자신과 매핑시킴.<br>Pod는 결국 PVC를 Volume으로 인식하여 사용하게 됨</p><ul><li>pvc_test.yaml</li></ul><pre><code>apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: pvc-test
spec:
  accessModes:
  - ReadWriteOnce
  volumeMode: Filesystem
  resources:
    requests:
      storage: 1Gi
  storageClassName: test
  selector:
    matchLabels:
      storage: prod
</code></pre><p>=> .spec.resources.requests 필드를 통해 필요로 하는 자원을 요청한다.<br>.spec.selector 를 이용하여 labels로 PV와 매핑할 수 있음</p><pre><code>$ kubectl get pv,pvc
NAME                       CAPACITY   ACCESS MODES   RECLAIM POLICY   STATUS   CLAIM              STORAGECLASS   REASON   AGE
persistentvolume/pv-test   1Gi        RWO            Delete           Bound    default/pvc-test   test                    6m47s

NAME                             STATUS   VOLUME    CAPACITY   ACCESS MODES   STORAGECLASS   AGE
persistentvolumeclaim/pvc-test   Bound    pv-test   1Gi        RWO            test           7s
</code></pre><p>=> pvc-test PVC가 pv-test PV와 연결된 것을 확인</p><ul><li>매핑되는 PV가 없을 때</li></ul><pre><code>$ kubectl get pv,pvc
NAME                       CAPACITY   ACCESS MODES   RECLAIM POLICY   STATUS      CLAIM   STORAGECLASS   REASON   AGE
persistentvolume/pv-test   1Gi        RWO            Delete           Available           test                    74s

NAME                             STATUS    VOLUME   CAPACITY   ACCESS MODES   STORAGECLASS   AGE
persistentvolumeclaim/pvc-test   Pending                                      manual         63s
</code></pre><p>=> PVC 에서 요청한 storageclass를 사용하는 PV가 없어서 PVC가 PV를 매핑하지 못하고 pending 상태임</p><ul><li>매핑되는 PV를 생성하고 다시 조회해보자</li></ul><pre><code>$ kubectl get pv,pvc
NAME                       CAPACITY   ACCESS MODES   RECLAIM POLICY   STATUS   CLAIM              STORAGECLASS   REASON   AGE
persistentvolume/pv-test   1Gi        RWO            Delete           Bound    default/pvc-test   manual                  2m53s

NAME                             STATUS   VOLUME    CAPACITY   ACCESS MODES   STORAGECLASS   AGE
persistentvolumeclaim/pvc-test   Bound    pv-test   1Gi        RWO            manual         2m42s
</code></pre><h3 id=pvc를-사용하는-pod를-생성해보자>PVC를 사용하는 Pod를 생성해보자<a hidden class=anchor aria-hidden=true href=#pvc를-사용하는-pod를-생성해보자>#</a></h3><pre><code>---
apiVersion: apps/v1
kind: Deployment
metadata: 
  name: nginx-pvc-test
  labels:
    app: nginx-pvc-test
spec:
  replicas: 2
  selector:
    matchLabels:
      app: nginx
  template:
    metadata:
      name: nginx 
      labels:
        app: nginx 
    spec:
      containers: 
      - name:  nginx
        image: nginx
        ports:
        - containerPort: 80
        volumeMounts:
        - name: pod-pvc-test
          mountPath: /pv-test
      volumes:
      - name: pod-pvc-test
        persistentVolumeClaim:
          claimName: pvc-test
</code></pre><p>=> .spec.template.spec.volumes[].name 으로 사용할 volume을 선언하는데<br>.spec.template.spec.volumes[].persistentVolumeClaim.cclaimName으로 이전에 생성해놓은 pvc-test PVC를 설정한다.<br>.spec.template.specc.containers.volumeMounts[].name에서 pvc-test volume을 conatiner의 /pv-test에 mount 한다고 설정한다.<br>그리고 이 pvc-test PVC는 pv-test 와 매핑되는데 pv-test 는 이전에 hostPath로 host의 /Users/nhn/Documents/kubernetes/volume/test/pv-test 디렉토리에 마운트됨</p><pre><code>$ kubectl describe pod/nginx-pvc-test-5d55669b9-vm8ml

Volumes:
  pod-pvc-test:
    Type:       PersistentVolumeClaim (a reference to a PersistentVolumeClaim in the same namespace)
    ClaimName:  pvc-test

$ kubectl describe persistentvolumeclaim/pvc-test

Volume:        pv-test
Mounted By:    nginx-pvc-test-5d55669b9-nkq68
               nginx-pvc-test-5d55669b9-vm8ml

$ kubectl describe persistentvolume/pv-test

Source:
    Type:          HostPath (bare host directory volume)
    Path:          /Users/nhn/Documents/kubernetes/volume/test/pv-test
</code></pre></div><footer class=post-footer><ul class=post-tags><li><a href=/tags/kubernetes/>kubernetes</a></li></ul></footer><div id=disqus_thread></div><script type=text/javascript>(function(){if(window.location.hostname=="localhost")
return;var dsq=document.createElement('script');dsq.type='text/javascript';dsq.async=true;var disqus_shortname='kimdubia';dsq.src='//'+disqus_shortname+'.disqus.com/embed.js';(document.getElementsByTagName('head')[0]||document.getElementsByTagName('body')[0]).appendChild(dsq);})();</script><noscript>Please enable JavaScript to view the <a href=https://disqus.com/?ref_noscript>comments powered by Disqus.</a></noscript><a href=https://disqus.com/ class=dsq-brlink>comments powered by <span class=logo-disqus>Disqus</span></a></article></main><footer class=footer><span>&copy; 2024 <a href>kimDuBiA</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://git.io/hugopapermod rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg></a><script>let menu=document.getElementById('menu')
menu.scrollLeft=localStorage.getItem("menu-scroll-position");menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft);}
document.querySelectorAll('a[href^="#"]').forEach(anchor=>{anchor.addEventListener("click",function(e){e.preventDefault();var id=this.getAttribute("href").substr(1);if(!window.matchMedia('(prefers-reduced-motion: reduce)').matches){document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({behavior:"smooth"});}else{document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();}
if(id==="top"){history.replaceState(null,null," ");}else{history.pushState(null,null,`#${id}`);}});});</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){if(document.body.scrollTop>800||document.documentElement.scrollTop>800){mybutton.style.visibility="visible";mybutton.style.opacity="1";}else{mybutton.style.visibility="hidden";mybutton.style.opacity="0";}};</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{if(document.body.className.includes("dark")){document.body.classList.remove('dark');localStorage.setItem("pref-theme",'light');}else{document.body.classList.add('dark');localStorage.setItem("pref-theme",'dark');}})</script><script>document.querySelectorAll('pre > code').forEach((codeblock)=>{const container=codeblock.parentNode.parentNode;const copybutton=document.createElement('button');copybutton.classList.add('copy-code');copybutton.innerText='copy';function copyingDone(){copybutton.innerText='copied!';setTimeout(()=>{copybutton.innerText='copy';},2000);}
copybutton.addEventListener('click',(cb)=>{if('clipboard'in navigator){navigator.clipboard.writeText(codeblock.textContent);copyingDone();return;}
const range=document.createRange();range.selectNodeContents(codeblock);const selection=window.getSelection();selection.removeAllRanges();selection.addRange(range);try{document.execCommand('copy');copyingDone();}catch(e){};selection.removeRange(range);});if(container.classList.contains("highlight")){container.appendChild(copybutton);}else if(container.parentNode.firstChild==container){}else if(codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"){codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(copybutton);}else{codeblock.parentNode.appendChild(copybutton);}});</script></body></html>
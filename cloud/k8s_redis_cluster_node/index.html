<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Kubernetes에서 redis cluster를 돌려보자 - Node | kimDuBiA</title><meta name=keywords content="kubernetes,redis"><meta name=description content="node? node 개념  Kubernetes 컴포넌트는 아래 세가지로 구분됨  master node worker node addon component (필수는아님)    Master node Master node는 kubernetes cluster 를 관리하는 node로 크게 아래의 컴포넌트로 이루어짐
 kube-apiserver : kubernetes 로 오는 모든 요청을 apiserver가 받아서 이 요청이 유효한지 검증함. kubernetes 내 모든 컴포넌트는 kube-apiserver를 통해 필요한 정보를 주고받음 kube-scheduler : Pod 생성 요청이 왔을 때 affinity, anti-affinity, resource requests 등의 Pod 생성조건을 확인하여 조건에 부합하는 node를 찾아 Pod를 생성하는 역할을 수행함 kube-controller-manager : node , network routing, loadbalancer, volume 을 관리하는 역할 etcd : kubernetes 의 status를 key value 로 저장하는 kubernetes의 database 역할  Worker node Pod 실행 및 관리 등 kubernetes내 오브젝트들의 실행 환경을 제공하고 관리함"><meta name=author content="kimdubi"><link rel=canonical href=/cloud/k8s_redis_cluster_node/><meta name=google-site-verification content="XYZabc"><meta name=yandex-verification content="XYZabc"><meta name=msvalidate.01 content="XYZabc"><link crossorigin=anonymous href=/assets/css/stylesheet.min.2dbef8664bbfb3e83a0a44fd4a8fc5010240dbcd1dbc1400753b928b497b8f5e.css integrity="sha256-Lb74Zku/s+g6CkT9So/FAQJA280dvBQAdTuSi0l7j14=" rel="preload stylesheet" as=style><script defer crossorigin=anonymous src=/assets/js/highlight.min.27cd435cc9ed6abb4b496581b151804f79f366c412620272bb94e2f5f598ebcc.js integrity="sha256-J81DXMntartLSWWBsVGAT3nzZsQSYgJyu5Ti9fWY68w=" onload=hljs.initHighlightingOnLoad();></script><link rel=icon href=%3Clink%20/%20abs%20url%3E><link rel=icon type=image/png sizes=16x16 href=%3Clink%20/%20abs%20url%3E><link rel=icon type=image/png sizes=32x32 href=%3Clink%20/%20abs%20url%3E><link rel=apple-touch-icon href=%3Clink%20/%20abs%20url%3E><link rel=mask-icon href=%3Clink%20/%20abs%20url%3E><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><meta name=generator content="Hugo 0.80.0"><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme: rgb(29, 30, 32);--entry: rgb(46, 46, 51);--primary: rgb(218, 218, 219);--secondary: rgb(155, 156, 157);--tertiary: rgb(65, 66, 68);--content: rgb(196, 196, 197);--hljs-bg: rgb(46, 46, 51);--code-bg: rgb(55, 56, 62);--border: rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><script type=application/javascript>var doNotTrack=false;if(!doNotTrack){(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');ga('create','UA-123-45','auto');ga('send','pageview');}</script><meta property="og:title" content="Kubernetes에서 redis cluster를 돌려보자 - Node"><meta property="og:description" content="node? node 개념  Kubernetes 컴포넌트는 아래 세가지로 구분됨  master node worker node addon component (필수는아님)    Master node Master node는 kubernetes cluster 를 관리하는 node로 크게 아래의 컴포넌트로 이루어짐
 kube-apiserver : kubernetes 로 오는 모든 요청을 apiserver가 받아서 이 요청이 유효한지 검증함. kubernetes 내 모든 컴포넌트는 kube-apiserver를 통해 필요한 정보를 주고받음 kube-scheduler : Pod 생성 요청이 왔을 때 affinity, anti-affinity, resource requests 등의 Pod 생성조건을 확인하여 조건에 부합하는 node를 찾아 Pod를 생성하는 역할을 수행함 kube-controller-manager : node , network routing, loadbalancer, volume 을 관리하는 역할 etcd : kubernetes 의 status를 key value 로 저장하는 kubernetes의 database 역할  Worker node Pod 실행 및 관리 등 kubernetes내 오브젝트들의 실행 환경을 제공하고 관리함"><meta property="og:type" content="article"><meta property="og:url" content="/cloud/k8s_redis_cluster_node/"><meta property="og:image" content="%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta property="article:section" content="cloud"><meta property="article:published_time" content="2021-10-06T13:03:06+09:00"><meta property="article:modified_time" content="2021-10-06T13:03:06+09:00"><meta property="og:site_name" content="kimDuBiA"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta name=twitter:title content="Kubernetes에서 redis cluster를 돌려보자 - Node"><meta name=twitter:description content="node? node 개념  Kubernetes 컴포넌트는 아래 세가지로 구분됨  master node worker node addon component (필수는아님)    Master node Master node는 kubernetes cluster 를 관리하는 node로 크게 아래의 컴포넌트로 이루어짐
 kube-apiserver : kubernetes 로 오는 모든 요청을 apiserver가 받아서 이 요청이 유효한지 검증함. kubernetes 내 모든 컴포넌트는 kube-apiserver를 통해 필요한 정보를 주고받음 kube-scheduler : Pod 생성 요청이 왔을 때 affinity, anti-affinity, resource requests 등의 Pod 생성조건을 확인하여 조건에 부합하는 node를 찾아 Pod를 생성하는 역할을 수행함 kube-controller-manager : node , network routing, loadbalancer, volume 을 관리하는 역할 etcd : kubernetes 의 status를 key value 로 저장하는 kubernetes의 database 역할  Worker node Pod 실행 및 관리 등 kubernetes내 오브젝트들의 실행 환경을 제공하고 관리함"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":2,"name":"Clouds","item":"/cloud/"},{"@type":"ListItem","position":3,"name":"Kubernetes에서 redis cluster를 돌려보자 - Node","item":"/cloud/k8s_redis_cluster_node/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Kubernetes에서 redis cluster를 돌려보자 - Node","name":"Kubernetes에서 redis cluster를 돌려보자 - Node","description":"node? node 개념  Kubernetes 컴포넌트는 아래 세가지로 구분됨  master node worker node addon component (필수는아님)    Master node Master node는 kubernetes cluster 를 관리하는 node로 크게 아래의 컴포넌트로 이루어짐\n kube-apiserver : kubernetes 로 오는 모든 요청을 apiserver가 받아서 이 요청이 유효한지 검증함. kubernetes 내 모든 컴포넌트는 kube-apiserver를 통해 필요한 정보를 주고받음 kube-scheduler : Pod 생성 요청이 왔을 때 affinity, anti-affinity, resource requests 등의 Pod 생성조건을 확인하여 조건에 부합하는 node를 찾아 Pod를 생성하는 역할을 수행함 kube-controller-manager : node , network routing, loadbalancer, volume 을 관리하는 역할 etcd : kubernetes 의 status를 key value 로 저장하는 kubernetes의 database 역할  Worker node Pod 실행 및 관리 등 kubernetes내 오브젝트들의 실행 환경을 제공하고 관리함","keywords":["kubernetes","redis"],"articleBody":" node? node 개념  Kubernetes 컴포넌트는 아래 세가지로 구분됨  master node worker node addon component (필수는아님)    Master node Master node는 kubernetes cluster 를 관리하는 node로 크게 아래의 컴포넌트로 이루어짐\n kube-apiserver : kubernetes 로 오는 모든 요청을 apiserver가 받아서 이 요청이 유효한지 검증함. kubernetes 내 모든 컴포넌트는 kube-apiserver를 통해 필요한 정보를 주고받음 kube-scheduler : Pod 생성 요청이 왔을 때 affinity, anti-affinity, resource requests 등의 Pod 생성조건을 확인하여 조건에 부합하는 node를 찾아 Pod를 생성하는 역할을 수행함 kube-controller-manager : node , network routing, loadbalancer, volume 을 관리하는 역할 etcd : kubernetes 의 status를 key value 로 저장하는 kubernetes의 database 역할  Worker node Pod 실행 및 관리 등 kubernetes내 오브젝트들의 실행 환경을 제공하고 관리함\n kubelet : kubernetes cluster 내 모든 node에서 실행되는 에이전트로 Pod 내 container를 실행하고 헬스체크하는 역할 kube-proxy : 노드에 들어오는 네트워크 트래픽을 포드 내의 컨테이너에게 라우팅하고 노드와 마스터간의 네트워크 통신을 관리하는 역할 Container runtime : container를 실행시키는 역할로 주로 docker를 사용함  worker node 간 pod 통신은 어떻게 이루어질까?  host01 의 Pod - host02의 Pod으로 접속할 때 host01의 cbr0 (10.168.20.1) - NAT - eth0 (192.168.10.11) - 라우터/게이트웨이로 도착 라우터/게이트웨이에는 192.168.30.0/24 로의 요청이 오면 어느 호스트로 보내야하는지에 대한 규칙을 가지고 있어서 host02로 전달함 이와 같은 구조를 host 간의 network 위에 별도의 network 가 또 존재한다 하여 overlay network라고 함  node 사용 현황 $ kubectl get nodes NAME STATUS ROLES AGE VERSION kimdubi-test-default-w-46niimovcith-node-0 Ready  46h v1.17.6 kimdubi-test-default-w-46niimovcith-node-1 Ready  46h v1.17.6 kimdubi-test-default-w-46niimovcith-node-2 Ready  46h v1.17.6  node template을 살펴보자 $ kubectl get node kimdubi-test-default-w-46niimovcith-node-0 -o yaml apiVersion: v1 kind: Node metadata: annotations: node.alpha.kubernetes.io/ttl: \"0\" volumes.kubernetes.io/controller-managed-attach-detach: \"true\" creationTimestamp: \"2021-02-21T05:46:58Z\" labels: beta.kubernetes.io/arch: amd64 beta.kubernetes.io/instance-type: 6efa0e80-84f1-49b2-b641-7737b878ee56 beta.kubernetes.io/os: linux failure-domain.beta.kubernetes.io/region: RegionOne failure-domain.beta.kubernetes.io/zone: kr-pub-b kubernetes.io/arch: amd64 kubernetes.io/hostname: kimdubi-test-default-w-46niimovcith-node-0 kubernetes.io/os: linux magnum.openstack.org/nodegroup: default-worker magnum.openstack.org/role: worker node.kubernetes.io/instance-type: 6efa0e80-84f1-49b2-b641-7737b878ee56 topology.kubernetes.io/region: RegionOne topology.kubernetes.io/zone: kr-pub-b name: kimdubi-test-default-w-46niimovcith-node-0 resourceVersion: \"602658\" selfLink: /api/v1/nodes/kimdubi-test-default-w-46niimovcith-node-0 uid: 8b0642fe-cc69-461c-bfd1-cb20647b60d5 spec: podCIDR: 10.100.0.0/24 podCIDRs: - 10.100.0.0/24 providerID: openstack:///e0d624b0-346a-44d8-8eae-448bd6b15701 status: addresses: - address: 192.168.0.16 type: InternalIP - address: kimdubi-test-default-w-46niimovcith-node-0 type: Hostname allocatable: cpu: \"1\" ephemeral-storage: \"18904622254\" hugepages-1Gi: \"0\" hugepages-2Mi: \"0\" memory: 1780444Ki pods: \"110\" capacity: cpu: \"1\" ephemeral-storage: 20512828Ki hugepages-1Gi: \"0\" hugepages-2Mi: \"0\" memory: 1882844Ki pods: \"110\" conditions: - lastHeartbeatTime: \"2021-02-23T04:15:34Z\" lastTransitionTime: \"2021-02-22T09:21:49Z\" message: kubelet has sufficient memory available reason: KubeletHasSufficientMemory status: \"False\" type: MemoryPressure - lastHeartbeatTime: \"2021-02-23T04:15:34Z\" lastTransitionTime: \"2021-02-22T09:21:49Z\" message: kubelet has no disk pressure reason: KubeletHasNoDiskPressure status: \"False\" type: DiskPressure - lastHeartbeatTime: \"2021-02-23T04:15:34Z\" lastTransitionTime: \"2021-02-22T09:21:49Z\" message: kubelet has sufficient PID available reason: KubeletHasSufficientPID status: \"False\" type: PIDPressure - lastHeartbeatTime: \"2021-02-23T04:15:34Z\" lastTransitionTime: \"2021-02-22T09:21:50Z\" message: kubelet is posting ready status reason: KubeletReady status: \"True\" type: Ready daemonEndpoints: kubeletEndpoint: Port: 10250 images: - names: - nvidia/k8s-device-plugin@sha256:631573a476b7e18512c5dae8990ea571bad3c14de3abaf6a8bc09a22c49be771 - nvidia/k8s-device-plugin:v0.7.0-centos7 sizeBytes: 264403050 - names: - kubernetesui/dashboard@sha256:24b77588e57e55da43db45df0c321de1f48488fa637926b342129783ff76abd4 - kubernetesui/dashboard:v2.0.0-rc7 sizeBytes: 220798514 - names: - k8s.gcr.io/kube-proxy@sha256:3691aecddfd13179dd6185a3dc4fd809c4964b64121c00b202cd972303edc4a9 - k8s.gcr.io/kube-proxy:v1.17.6 sizeBytes: 116521281 - names: - k8s.gcr.io/node-problem-detector@sha256:f7a97be0fae649f95228bd89836590fb3dfddadc98a48e4be3fee1b19854bf9b - k8s.gcr.io/node-problem-detector:v0.8.2 sizeBytes: 110047285 - names: - bitnami/redis-cluster@sha256:dfedcaa03878564f6eb75c101a66d8ecd18a9558971ade5c82611bfa9fb6da96 - bitnami/redis-cluster:6.0.10-debian-10-r5 sizeBytes: 100302970 - names: - k8s.gcr.io/autoscaling/cluster-autoscaler@sha256:d6e51b58808b5abe74b57666114efab748a6d8ba73afdb24cd2a7f91f11c4b1b - k8s.gcr.io/autoscaling/cluster-autoscaler:v1.19.0 sizeBytes: 90379091 - names: - quay.io/coreos/flannel@sha256:6d451d92c921f14bfb38196aacb6e506d4593c5b3c9d40a8b8a2506010dc3e10 - quay.io/coreos/flannel:v0.12.0-amd64 sizeBytes: 52767393 - names: - gcr.io/google_containers/cluster-proportional-autoscaler-amd64@sha256:791836c2a2471ecb23a975cf12835f2a35ada3f9d841f3f1a363b83eca99e2aa - gcr.io/google_containers/cluster-proportional-autoscaler-amd64:1.1.2 sizeBytes: 50485461 - names: - quay.io/coreos/flannel-cni@sha256:734b4222110980abd0abe74974b6ca36452d26bdd2a20e25f37fdf7fdc2da170 - quay.io/coreos/flannel-cni:v0.3.0 sizeBytes: 49786179 - names: - coredns/coredns@sha256:7ec975f167d815311a7136c32e70735f0d00b73781365df1befd46ed35bd4fe7 - coredns/coredns:1.6.5 sizeBytes: 41578211 - names: - k8s.gcr.io/metrics-server-amd64@sha256:78938f933822856f443e6827fe5b37d6cc2f74ae888ac8b33d06fdbe5f8c658b - k8s.gcr.io/metrics-server-amd64:v0.3.1 sizeBytes: 40767713 - names: - kubernetesui/metrics-scraper@sha256:555981a24f184420f3be0c79d4efb6c948a85cfce84034f85a563f4151a81cbf - kubernetesui/metrics-scraper:v1.0.4 sizeBytes: 36937728 - names: - k8s.gcr.io/pause@sha256:f78411e19d84a252e53bff71a4407a5686c46983a2c2eeed83929b888179acea - k8s.gcr.io/pause:3.1 sizeBytes: 742472 nodeInfo: architecture: amd64 bootID: c5eda8c3-5d63-45db-854f-6a563e9a7870 containerRuntimeVersion: docker://19.3.13 kernelVersion: 3.10.0-862.14.4.el7.x86_64 kubeProxyVersion: v1.17.6 kubeletVersion: v1.17.6 machineID: e0d624b0346a44d88eae448bd6b15701 operatingSystem: linux osImage: CentOS Linux 7 (Core) systemUUID: E0D624B0-346A-44D8-8EAE-448BD6B15701 volumesAttached: - devicePath: /dev/vdc name: kubernetes.io/cinder/5aa9bfc5-5cac-48ba-a9dc-f1e19926763d - devicePath: /dev/vdb name: kubernetes.io/cinder/01f43c11-b446-48ee-8898-bdd3f247dfbd volumesInUse: - kubernetes.io/cinder/01f43c11-b446-48ee-8898-bdd3f247dfbd - kubernetes.io/cinder/5aa9bfc5-5cac-48ba-a9dc-f1e19926763d  .metadata.labels  node의 labels 은 주로 Pod 의 affinity , antiAffinity 에 사용되어 Pod이 특정 node에 생성될 수 있도록 할 때 사용됨  .status.conditions  node 의 현재 상태를 확인할 수 있음 주로 kubectl decribe node node명으로 확인함 memory나 disk 가 부족한지 등의 상태가 나오기 때문에 Pod 이 생성 안되거나 이상이 있을 때 확인해야하는 정보임  ","wordCount":"605","inLanguage":"en","datePublished":"2021-10-06T13:03:06+09:00","dateModified":"2021-10-06T13:03:06+09:00","author":{"@type":"Person","name":"kimdubi"},"mainEntityOfPage":{"@type":"WebPage","@id":"/cloud/k8s_redis_cluster_node/"},"publisher":{"@type":"Organization","name":"kimDuBiA","logo":{"@type":"ImageObject","url":"%3Clink%20/%20abs%20url%3E"}}}</script></head><body id=top><script>if(localStorage.getItem("pref-theme")==="dark"){document.body.classList.add('dark');}else if(localStorage.getItem("pref-theme")==="light"){document.body.classList.remove('dark')}else if(window.matchMedia('(prefers-color-scheme: dark)').matches){document.body.classList.add('dark');}</script><header class=header><nav class=nav><div class=logo><a href accesskey=h title="Home (Alt + H)">Home</a>
<span class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></span></div><ul id=menu><li><a href=/ title=Home><span>Home</span></a></li><li><a href=/categories/ title=categories><span>categories</span></a></li><li><a href=/tags/ title=tags><span>tags</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href>Home</a>&nbsp;»&nbsp;<a href=/cloud/>Clouds</a></div><h1 class=post-title>Kubernetes에서 redis cluster를 돌려보자 - Node</h1><div class=post-meta>October 6, 2021&nbsp;·&nbsp;3 min&nbsp;·&nbsp;kimdubi</div></header><div class=toc><details><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><ul><li><a href=#node aria-label=node?>node?</a><ul><li><a href=#node-%ea%b0%9c%eb%85%90 aria-label="node 개념">node 개념</a><ul><li><a href=#master-node aria-label="Master node">Master node</a></li><li><a href=#worker-node aria-label="Worker node">Worker node</a></li><li><a href=#worker-node-%ea%b0%84-pod-%ed%86%b5%ec%8b%a0%ec%9d%80-%ec%96%b4%eb%96%bb%ea%b2%8c-%ec%9d%b4%eb%a3%a8%ec%96%b4%ec%a7%88%ea%b9%8c aria-label="worker node 간 pod 통신은 어떻게 이루어질까?">worker node 간 pod 통신은 어떻게 이루어질까?</a></li><li><a href=#node-%ec%82%ac%ec%9a%a9-%ed%98%84%ed%99%a9 aria-label="node 사용 현황">node 사용 현황</a></li></ul></li></ul></li><li><a href=#node-template%ec%9d%84-%ec%82%b4%ed%8e%b4%eb%b3%b4%ec%9e%90 aria-label="node template을 살펴보자">node template을 살펴보자</a><ul><ul><li><a href=#metadatalabels aria-label=.metadata.labels>.metadata.labels</a></li><li><a href=#statusconditions aria-label=.status.conditions>.status.conditions</a></li></ul></ul></li></ul></div></details></div><div class=post-content><hr><h1 id=node>node?<a hidden class=anchor aria-hidden=true href=#node>#</a></h1><h2 id=node-개념>node 개념<a hidden class=anchor aria-hidden=true href=#node-개념>#</a></h2><p><img loading=lazy src=https://raw.githubusercontent.com/kimdubi/kimdubi.github.io/master/images/cloud/k8s/k8s_redis_node01.png alt></p><ul><li>Kubernetes 컴포넌트는 아래 세가지로 구분됨<ul><li>master node</li><li>worker node</li><li>addon component (필수는아님)</li></ul></li></ul><h3 id=master-node>Master node<a hidden class=anchor aria-hidden=true href=#master-node>#</a></h3><p>Master node는 kubernetes cluster 를 관리하는 node로 크게 아래의 컴포넌트로 이루어짐</p><ul><li>kube-apiserver : kubernetes 로 오는 모든 요청을 apiserver가 받아서 이 요청이 유효한지 검증함. kubernetes 내 모든 컴포넌트는 kube-apiserver를 통해 필요한 정보를 주고받음</li><li>kube-scheduler : Pod 생성 요청이 왔을 때 affinity, anti-affinity, resource requests 등의 Pod 생성조건을 확인하여 조건에 부합하는 node를 찾아 Pod를 생성하는 역할을 수행함</li><li>kube-controller-manager : node , network routing, loadbalancer, volume 을 관리하는 역할</li><li>etcd : kubernetes 의 status를 key value 로 저장하는 kubernetes의 database 역할</li></ul><h3 id=worker-node>Worker node<a hidden class=anchor aria-hidden=true href=#worker-node>#</a></h3><p>Pod 실행 및 관리 등 kubernetes내 오브젝트들의 실행 환경을 제공하고 관리함</p><ul><li>kubelet : kubernetes cluster 내 모든 node에서 실행되는 에이전트로 Pod 내 container를 실행하고 헬스체크하는 역할</li><li>kube-proxy : 노드에 들어오는 네트워크 트래픽을 포드 내의 컨테이너에게 라우팅하고 노드와 마스터간의 네트워크 통신을 관리하는 역할</li><li>Container runtime : container를 실행시키는 역할로 주로 docker를 사용함</li></ul><h3 id=worker-node-간-pod-통신은-어떻게-이루어질까>worker node 간 pod 통신은 어떻게 이루어질까?<a hidden class=anchor aria-hidden=true href=#worker-node-간-pod-통신은-어떻게-이루어질까>#</a></h3><p><img loading=lazy src=https://raw.githubusercontent.com/kimdubi/kimdubi.github.io/master/images/cloud/k8s/k8s_redis_node02.png alt></p><ul><li>host01 의 Pod -> host02의 Pod으로 접속할 때 host01의 cbr0 (10.168.20.1) -> NAT -> eth0 (192.168.10.11) -> 라우터/게이트웨이로 도착</li><li>라우터/게이트웨이에는 192.168.30.0/24 로의 요청이 오면 어느 호스트로 보내야하는지에 대한 규칙을 가지고 있어서 host02로 전달함</li><li>이와 같은 구조를 host 간의 network 위에 별도의 network 가 또 존재한다 하여 overlay network라고 함</li></ul><h3 id=node-사용-현황>node 사용 현황<a hidden class=anchor aria-hidden=true href=#node-사용-현황>#</a></h3><p><img loading=lazy src=https://raw.githubusercontent.com/kimdubi/kimdubi.github.io/master/images/cloud/k8s/k8s_redis_node03.png alt></p><pre><code>$ kubectl get nodes
NAME                                         STATUS   ROLES    AGE   VERSION
kimdubi-test-default-w-46niimovcith-node-0   Ready    &lt;none&gt;   46h   v1.17.6
kimdubi-test-default-w-46niimovcith-node-1   Ready    &lt;none&gt;   46h   v1.17.6
kimdubi-test-default-w-46niimovcith-node-2   Ready    &lt;none&gt;   46h   v1.17.6
</code></pre><h1 id=node-template을-살펴보자>node template을 살펴보자<a hidden class=anchor aria-hidden=true href=#node-template을-살펴보자>#</a></h1><pre><code>$ kubectl get node  kimdubi-test-default-w-46niimovcith-node-0 -o yaml
apiVersion: v1
kind: Node
metadata:
  annotations:
    node.alpha.kubernetes.io/ttl: &quot;0&quot;
    volumes.kubernetes.io/controller-managed-attach-detach: &quot;true&quot;
  creationTimestamp: &quot;2021-02-21T05:46:58Z&quot;
  labels:
    beta.kubernetes.io/arch: amd64
    beta.kubernetes.io/instance-type: 6efa0e80-84f1-49b2-b641-7737b878ee56
    beta.kubernetes.io/os: linux
    failure-domain.beta.kubernetes.io/region: RegionOne
    failure-domain.beta.kubernetes.io/zone: kr-pub-b
    kubernetes.io/arch: amd64
    kubernetes.io/hostname: kimdubi-test-default-w-46niimovcith-node-0
    kubernetes.io/os: linux
    magnum.openstack.org/nodegroup: default-worker
    magnum.openstack.org/role: worker
    node.kubernetes.io/instance-type: 6efa0e80-84f1-49b2-b641-7737b878ee56
    topology.kubernetes.io/region: RegionOne
    topology.kubernetes.io/zone: kr-pub-b
  name: kimdubi-test-default-w-46niimovcith-node-0
  resourceVersion: &quot;602658&quot;
  selfLink: /api/v1/nodes/kimdubi-test-default-w-46niimovcith-node-0
  uid: 8b0642fe-cc69-461c-bfd1-cb20647b60d5
spec:
  podCIDR: 10.100.0.0/24
  podCIDRs:
  - 10.100.0.0/24
  providerID: openstack:///e0d624b0-346a-44d8-8eae-448bd6b15701
status:
  addresses:
  - address: 192.168.0.16
    type: InternalIP
  - address: kimdubi-test-default-w-46niimovcith-node-0
    type: Hostname
  allocatable:
    cpu: &quot;1&quot;
    ephemeral-storage: &quot;18904622254&quot;
    hugepages-1Gi: &quot;0&quot;
    hugepages-2Mi: &quot;0&quot;
    memory: 1780444Ki
    pods: &quot;110&quot;
  capacity:
    cpu: &quot;1&quot;
    ephemeral-storage: 20512828Ki
    hugepages-1Gi: &quot;0&quot;
    hugepages-2Mi: &quot;0&quot;
    memory: 1882844Ki
    pods: &quot;110&quot;
  conditions:
  - lastHeartbeatTime: &quot;2021-02-23T04:15:34Z&quot;
    lastTransitionTime: &quot;2021-02-22T09:21:49Z&quot;
    message: kubelet has sufficient memory available
    reason: KubeletHasSufficientMemory
    status: &quot;False&quot;
    type: MemoryPressure
  - lastHeartbeatTime: &quot;2021-02-23T04:15:34Z&quot;
    lastTransitionTime: &quot;2021-02-22T09:21:49Z&quot;
    message: kubelet has no disk pressure
    reason: KubeletHasNoDiskPressure
    status: &quot;False&quot;
    type: DiskPressure
  - lastHeartbeatTime: &quot;2021-02-23T04:15:34Z&quot;
    lastTransitionTime: &quot;2021-02-22T09:21:49Z&quot;
    message: kubelet has sufficient PID available
    reason: KubeletHasSufficientPID
    status: &quot;False&quot;
    type: PIDPressure
  - lastHeartbeatTime: &quot;2021-02-23T04:15:34Z&quot;
    lastTransitionTime: &quot;2021-02-22T09:21:50Z&quot;
    message: kubelet is posting ready status
    reason: KubeletReady
    status: &quot;True&quot;
    type: Ready
  daemonEndpoints:
    kubeletEndpoint:
      Port: 10250
  images:
  - names:
    - nvidia/k8s-device-plugin@sha256:631573a476b7e18512c5dae8990ea571bad3c14de3abaf6a8bc09a22c49be771
    - nvidia/k8s-device-plugin:v0.7.0-centos7
    sizeBytes: 264403050
  - names:
    - kubernetesui/dashboard@sha256:24b77588e57e55da43db45df0c321de1f48488fa637926b342129783ff76abd4
    - kubernetesui/dashboard:v2.0.0-rc7
    sizeBytes: 220798514
  - names:
    - k8s.gcr.io/kube-proxy@sha256:3691aecddfd13179dd6185a3dc4fd809c4964b64121c00b202cd972303edc4a9
    - k8s.gcr.io/kube-proxy:v1.17.6
    sizeBytes: 116521281
  - names:
    - k8s.gcr.io/node-problem-detector@sha256:f7a97be0fae649f95228bd89836590fb3dfddadc98a48e4be3fee1b19854bf9b
    - k8s.gcr.io/node-problem-detector:v0.8.2
    sizeBytes: 110047285
  - names:
    - bitnami/redis-cluster@sha256:dfedcaa03878564f6eb75c101a66d8ecd18a9558971ade5c82611bfa9fb6da96
    - bitnami/redis-cluster:6.0.10-debian-10-r5
    sizeBytes: 100302970
  - names:
    - k8s.gcr.io/autoscaling/cluster-autoscaler@sha256:d6e51b58808b5abe74b57666114efab748a6d8ba73afdb24cd2a7f91f11c4b1b
    - k8s.gcr.io/autoscaling/cluster-autoscaler:v1.19.0
    sizeBytes: 90379091
  - names:
    - quay.io/coreos/flannel@sha256:6d451d92c921f14bfb38196aacb6e506d4593c5b3c9d40a8b8a2506010dc3e10
    - quay.io/coreos/flannel:v0.12.0-amd64
    sizeBytes: 52767393
  - names:
    - gcr.io/google_containers/cluster-proportional-autoscaler-amd64@sha256:791836c2a2471ecb23a975cf12835f2a35ada3f9d841f3f1a363b83eca99e2aa
    - gcr.io/google_containers/cluster-proportional-autoscaler-amd64:1.1.2
    sizeBytes: 50485461
  - names:
    - quay.io/coreos/flannel-cni@sha256:734b4222110980abd0abe74974b6ca36452d26bdd2a20e25f37fdf7fdc2da170
    - quay.io/coreos/flannel-cni:v0.3.0
    sizeBytes: 49786179
  - names:
    - coredns/coredns@sha256:7ec975f167d815311a7136c32e70735f0d00b73781365df1befd46ed35bd4fe7
    - coredns/coredns:1.6.5
    sizeBytes: 41578211
  - names:
    - k8s.gcr.io/metrics-server-amd64@sha256:78938f933822856f443e6827fe5b37d6cc2f74ae888ac8b33d06fdbe5f8c658b
    - k8s.gcr.io/metrics-server-amd64:v0.3.1
    sizeBytes: 40767713
  - names:
    - kubernetesui/metrics-scraper@sha256:555981a24f184420f3be0c79d4efb6c948a85cfce84034f85a563f4151a81cbf
    - kubernetesui/metrics-scraper:v1.0.4
    sizeBytes: 36937728
  - names:
    - k8s.gcr.io/pause@sha256:f78411e19d84a252e53bff71a4407a5686c46983a2c2eeed83929b888179acea
    - k8s.gcr.io/pause:3.1
    sizeBytes: 742472
  nodeInfo:
    architecture: amd64
    bootID: c5eda8c3-5d63-45db-854f-6a563e9a7870
    containerRuntimeVersion: docker://19.3.13
    kernelVersion: 3.10.0-862.14.4.el7.x86_64
    kubeProxyVersion: v1.17.6
    kubeletVersion: v1.17.6
    machineID: e0d624b0346a44d88eae448bd6b15701
    operatingSystem: linux
    osImage: CentOS Linux 7 (Core)
    systemUUID: E0D624B0-346A-44D8-8EAE-448BD6B15701
  volumesAttached:
  - devicePath: /dev/vdc
    name: kubernetes.io/cinder/5aa9bfc5-5cac-48ba-a9dc-f1e19926763d
  - devicePath: /dev/vdb
    name: kubernetes.io/cinder/01f43c11-b446-48ee-8898-bdd3f247dfbd
  volumesInUse:
  - kubernetes.io/cinder/01f43c11-b446-48ee-8898-bdd3f247dfbd
  - kubernetes.io/cinder/5aa9bfc5-5cac-48ba-a9dc-f1e19926763d
</code></pre><h3 id=metadatalabels>.metadata.labels<a hidden class=anchor aria-hidden=true href=#metadatalabels>#</a></h3><ul><li>node의 labels 은 주로 Pod 의 affinity , antiAffinity 에 사용되어 Pod이 특정 node에 생성될 수 있도록 할 때 사용됨</li></ul><h3 id=statusconditions>.status.conditions<a hidden class=anchor aria-hidden=true href=#statusconditions>#</a></h3><ul><li>node 의 현재 상태를 확인할 수 있음 주로 kubectl decribe node node명으로 확인함</li><li>memory나 disk 가 부족한지 등의 상태가 나오기 때문에 Pod 이 생성 안되거나 이상이 있을 때 확인해야하는 정보임</li></ul></div><footer class=post-footer><ul class=post-tags><li><a href=/tags/kubernetes/>kubernetes</a></li><li><a href=/tags/redis/>redis</a></li></ul></footer><div id=disqus_thread></div><script type=text/javascript>(function(){if(window.location.hostname=="localhost")
return;var dsq=document.createElement('script');dsq.type='text/javascript';dsq.async=true;var disqus_shortname='kimdubia';dsq.src='//'+disqus_shortname+'.disqus.com/embed.js';(document.getElementsByTagName('head')[0]||document.getElementsByTagName('body')[0]).appendChild(dsq);})();</script><noscript>Please enable JavaScript to view the <a href=https://disqus.com/?ref_noscript>comments powered by Disqus.</a></noscript><a href=https://disqus.com/ class=dsq-brlink>comments powered by <span class=logo-disqus>Disqus</span></a></article></main><footer class=footer><span>&copy; 2021 <a href>kimDuBiA</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://git.io/hugopapermod rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg></a><script>let menu=document.getElementById('menu')
menu.scrollLeft=localStorage.getItem("menu-scroll-position");menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft);}
document.querySelectorAll('a[href^="#"]').forEach(anchor=>{anchor.addEventListener("click",function(e){e.preventDefault();var id=this.getAttribute("href").substr(1);if(!window.matchMedia('(prefers-reduced-motion: reduce)').matches){document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({behavior:"smooth"});}else{document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();}
if(id==="top"){history.replaceState(null,null," ");}else{history.pushState(null,null,`#${id}`);}});});</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){if(document.body.scrollTop>800||document.documentElement.scrollTop>800){mybutton.style.visibility="visible";mybutton.style.opacity="1";}else{mybutton.style.visibility="hidden";mybutton.style.opacity="0";}};</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{if(document.body.className.includes("dark")){document.body.classList.remove('dark');localStorage.setItem("pref-theme",'light');}else{document.body.classList.add('dark');localStorage.setItem("pref-theme",'dark');}})</script><script>document.querySelectorAll('pre > code').forEach((codeblock)=>{const container=codeblock.parentNode.parentNode;const copybutton=document.createElement('button');copybutton.classList.add('copy-code');copybutton.innerText='copy';function copyingDone(){copybutton.innerText='copied!';setTimeout(()=>{copybutton.innerText='copy';},2000);}
copybutton.addEventListener('click',(cb)=>{if('clipboard'in navigator){navigator.clipboard.writeText(codeblock.textContent);copyingDone();return;}
const range=document.createRange();range.selectNodeContents(codeblock);const selection=window.getSelection();selection.removeAllRanges();selection.addRange(range);try{document.execCommand('copy');copyingDone();}catch(e){};selection.removeRange(range);});if(container.classList.contains("highlight")){container.appendChild(copybutton);}else if(container.parentNode.firstChild==container){}else if(codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"){codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(copybutton);}else{codeblock.parentNode.appendChild(copybutton);}});</script></body></html>